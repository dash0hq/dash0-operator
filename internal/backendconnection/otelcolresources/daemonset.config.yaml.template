connectors:
  forward/logs:

exporters:
{{- if .DevelopmentMode }}
  debug: {}
{{- end }}
{{- range $i, $exporter := .Exporters }}
  {{ $exporter.Name }}:
    endpoint: "{{ $exporter.Endpoint }}"
{{ if $exporter.Insecure }}
    tls:
      insecure: true
{{ end }}
{{- if $exporter.Headers }}
    headers:
{{- range $i, $header := $exporter.Headers }}
      "{{ $header.Name }}": "{{ $header.Value }}"
{{- end }}
{{- end }}
{{- if $exporter.Encoding }}
    encoding: "{{ $exporter.Encoding }}"
{{- end }}
{{- end }}

extensions:
  health_check:
    endpoint: "{{ .SelfIpReference }}:13133"
  file_storage/filelogreceiver_offsets:
    directory: /var/otelcol/filelogreceiver_offsets
    timeout: 1s

processors:
  batch: {}

  resourcedetection:
    detectors:
    - system
    - eks
    - ecs
    - ec2
    - gcp
    - aks
    - azure
    - k8snode

  filter/only_dash0_monitored_resources:
    error_mode: ignore
    traces:
      span:
      - 'resource.attributes["dash0.monitoring.instrumented"] != "true"'
    metrics:
      metric:
      datapoint:
      - 'resource.attributes["dash0.monitoring.instrumented"] != "true"'
    logs:
      log_record:
      - 'resource.attributes["dash0.monitoring.instrumented"] != "true"'
  k8sattributes:
    extract:
      metadata:
      - k8s.namespace.name
      - k8s.deployment.name
      - k8s.statefulset.name
      - k8s.daemonset.name
      - k8s.cronjob.name
      - k8s.job.name
      - k8s.node.name
      - k8s.pod.name
      - k8s.pod.uid
      - k8s.pod.start_time
      labels:
      - key: dash0.com/instrumented
        tag_name: dash0.monitoring.instrumented
        from: pod
    filter:
      node_from_env_var: K8S_NODE_NAME
    passthrough: false
    pod_association:
    - sources:
      - from: resource_attribute
        name: k8s.pod.ip
    - sources:
      - from: resource_attribute
        name: k8s.pod.uid
    - sources:
      - from: connection
  memory_limiter:
    check_interval: 5s
    limit_percentage: 80
    spike_limit_percentage: 25

receivers:
  otlp:
    protocols:
      grpc:
        endpoint: "{{ .SelfIpReference }}:4317"
        max_recv_msg_size_mib: 8388608
      http:
        endpoint: "{{ .SelfIpReference }}:4318"

{{- if .NodeLevelMetricsCollectionEnabled }}
  kubeletstats:
    auth_type: serviceAccount
    collection_interval: 20s
    endpoint: ${env:K8S_NODE_NAME}:10250
    metrics:
      # deprecated -> container.cpu.usage
      container.cpu.utilization:
        enabled: false
      # deprecated -> k8s.node.cpu.usage
      k8s.node.cpu.utilization:
        enabled: false
      # deprecated -> k8s.pod.cpu.usage
      k8s.pod.cpu.utilization:
        enabled: false

{{- if .DevelopmentMode }}
{{- /*
On Docker Desktop, Kind, etc. the API server uses a self-signed cert. Scraping will not work without
insecure_skip_verify=true in these environments:

kubeletstatsreceiver@v0.106.1/scraper.go:104 call to /stats/summary endpoint failed
{"kind": "receiver", "name": "kubeletstats", "data_type": "metrics", "error": "Get
\"https://docker-desktop:10250/stats/summary\": tls: failed to verify certificate: x509: certificate signed by unknown
authority"}

Thus we add this parameter when the helm chart is installed with --set operator.developmentMode=true for local tests and
e2e tests. */}}
    insecure_skip_verify: true
{{- end }}
{{- end }}

{{- $hasPrometheusScrapingEnabledForAtLeastOneNamespace := gt (len .NamespacesWithPrometheusScraping) 0 }}

{{- if $hasPrometheusScrapingEnabledForAtLeastOneNamespace }}
  prometheus:
    config:
{{- /*
This particular set of scrape config jobs (kubernetes-service-endpoints, kubernetes-service-endpoints-slow,
kubernetes-pods, kubernetes-pods-slow) is mostly a copy of
https://github.com/prometheus-community/helm-charts/blob/5adf0ee898e8e5430471cb43a5f9532745c22f81/charts/prometheus/values.yaml
to be compatible with the well-known configuration via annotations.
*/}}
      scrape_configs:

      # The relabeling allows the actual pod scrape endpoint to be configured via the
      # following annotations:
      #
      # * `prometheus.io/scrape`: Only scrape pods that have a value of `true`,
      # except if `prometheus.io/scrape-slow` is set to `true` as well.
      # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need
      # to set this to `https` & most likely set the `tls_config` of the scrape config.
      # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
      # * `prometheus.io/port`: Scrape the pod on the indicated port instead of the default of `9102`.
      - job_name: 'kubernetes-pods'
        honor_labels: true

        kubernetes_sd_configs:
          - role: pod
            # only scrape data from pods running on the same node as collector
            selectors:
              - role: pod
                field: "spec.nodeName=${K8S_NODE_NAME}"
            namespaces:
              names:
              {{- range $i, $namespace := .NamespacesWithPrometheusScraping }}
              - {{ $namespace }}
              {{- end }}

        relabel_configs:
          - source_labels: [ __meta_kubernetes_namespace ]
            regex: kube-system
            action: drop
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape_slow]
            action: drop
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
            action: replace
            regex: (https?)
            target_label: __scheme__
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port, __meta_kubernetes_pod_ip]
            action: replace
            regex: (\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})
            replacement: '[$2]:$1'
            target_label: __address__
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port, __meta_kubernetes_pod_ip]
            action: replace
            regex: (\d+);((([0-9]+?)(\.|$)){4})
            replacement: $2:$1
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
            replacement: __param_$1
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: pod
          - source_labels: [__meta_kubernetes_pod_phase]
            regex: Pending|Succeeded|Failed|Completed
            action: drop
          - source_labels: [__meta_kubernetes_pod_node_name]
            action: replace
            target_label: node

      # Example Scrape config for pods which should be scraped slower. An useful example
      # would be stackriver-exporter which queries an API on every scrape of the pod
      #
      # The relabeling allows the actual pod scrape endpoint to be configured via the
      # following annotations:
      #
      # * `prometheus.io/scrape-slow`: Only scrape pods that have a value of `true`
      # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need
      # to set this to `https` & most likely set the `tls_config` of the scrape config.
      # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
      # * `prometheus.io/port`: Scrape the pod on the indicated port instead of the default of `9102`.
      - job_name: 'kubernetes-pods-slow'
        honor_labels: true

        scrape_interval: 5m
        scrape_timeout: 30s

        kubernetes_sd_configs:
          - role: pod
            # only scrape data from pods running on the same node as collector
            selectors:
              - role: pod
                field: "spec.nodeName=${K8S_NODE_NAME}"
            namespaces:
              names:
              {{- range $i, $namespace := .NamespacesWithPrometheusScraping }}
              - {{ $namespace }}
              {{- end }}

        relabel_configs:
          - source_labels: [ __meta_kubernetes_namespace ]
            regex: kube-system
            action: drop
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape_slow]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
            action: replace
            regex: (https?)
            target_label: __scheme__
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port, __meta_kubernetes_pod_ip]
            action: replace
            regex: (\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})
            replacement: '[$2]:$1'
            target_label: __address__
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port, __meta_kubernetes_pod_ip]
            action: replace
            regex: (\d+);((([0-9]+?)(\.|$)){4})
            replacement: $2:$1
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
            replacement: __param_$1
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: pod
          - source_labels: [__meta_kubernetes_pod_phase]
            regex: Pending|Succeeded|Failed|Completed
            action: drop
          - source_labels: [__meta_kubernetes_pod_node_name]
            action: replace
            target_label: node
{{- end }}

  # TODO Turn on conditionally for monitored namespaces
  filelog/monitored_pods:
    include:
    - /var/log/pods/*/*/*.log
    exclude:
{{- range $i, $namespace := .IgnoreLogsFromNamespaces }}
    - /var/log/pods/{{ $namespace }}_*/*/*.log
{{- end}}
    storage: file_storage/filelogreceiver_offsets
    include_file_path: true
    include_file_name: false
    include_file_record_number: true
    operators:
    # Find out which format is used by kubernetes
    - type: router
      id: get-format
      routes:
      - output: parser-docker
        expr: 'body matches "^\\{"'
      - output: parser-crio
        expr: 'body matches "^[^ Z]+ "'
      - output: parser-containerd
        expr: 'body matches "^[^ Z]+Z"'
    # Parse CRI-O format
    - type: regex_parser
      id: parser-crio
      regex: '^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$'
      output: extract_metadata_from_filepath
      timestamp:
        parse_from: attributes.time
        layout_type: gotime
        layout: '2006-01-02T15:04:05.999999999Z07:00'
    # Parse CRI-Containerd format
    - type: regex_parser
      id: parser-containerd
      regex: '^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$'
      output: extract_metadata_from_filepath
      timestamp:
        parse_from: attributes.time
        layout: '%Y-%m-%dT%H:%M:%S.%LZ'
    # Parse Docker format
    - type: json_parser
      id: parser-docker
      output: parser-docker-body
      timestamp:
        parse_from: attributes.time
        layout: '%Y-%m-%dT%H:%M:%S.%LZ'
    - type: json_parser
      id: parser-docker-body
      output: extract_metadata_from_filepath
      parse_from: body
      parse_to: attributes
    - type: move
      from: attributes.log
      to: body
    # Extract metadata from file path
    - type: regex_parser
      id: extract_metadata_from_filepath
      regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]{36})\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$'
      parse_from: attributes["log.file.path"]
      cache:
        size: 128 # default maximum amount of Pods per Node is 110
    # Rename attributes
    - type: move
      from: attributes.stream
      to: attributes["log.iostream"]
    - type: move
      from: attributes.container_name
      to: resource["k8s.container.name"]
    - type: move
      from: attributes.namespace
      to: resource["k8s.namespace.name"]
    - type: move
      from: attributes.pod_name
      to: resource["k8s.pod.name"]
    - type: move
      from: attributes.restart_count
      to: resource["k8s.container.restart_count"]
    - type: move
      from: attributes.uid
      to: resource["k8s.pod.uid"]
    # Delete unnecessary attributes
    - type: remove
      field: attributes.time

service:
  extensions:
  - health_check
  - file_storage/filelogreceiver_offsets
  pipelines:
    traces/downstream:
      receivers:
      - otlp
      processors:
      - k8sattributes
      - resourcedetection
      - memory_limiter
      - batch
      exporters:
      {{- if .DevelopmentMode }}
      - debug
      {{- end }}
      {{- range $i, $exporter := .Exporters }}
      - {{ $exporter.Name }}
      {{- end }}

    metrics/downstream:
      receivers:
      - otlp
{{- if .NodeLevelMetricsCollectionEnabled }}
      - kubeletstats
{{- end }}
{{- if $hasPrometheusScrapingEnabledForAtLeastOneNamespace }}
      - prometheus
{{- end }}
      processors:
      - k8sattributes
      - resourcedetection
      - memory_limiter
      - batch
      exporters:
      {{- if .DevelopmentMode }}
      - debug
      {{- end }}
      {{- range $i, $exporter := .Exporters }}
      - {{ $exporter.Name }}
      {{- end }}

    logs/otlp:
      receivers:
      - otlp
      processors:
      - k8sattributes
      exporters:
      - forward/logs

    logs/monitoredpods:
      receivers:
      - filelog/monitored_pods
      processors:
      - k8sattributes
      - filter/only_dash0_monitored_resources
      exporters:
      - forward/logs

    logs/downstream:
      receivers:
      - forward/logs
      processors:
      - resourcedetection
      - memory_limiter
      - batch
      exporters:
      {{- if .DevelopmentMode }}
      - debug
      {{- end }}
      {{- range $i, $exporter := .Exporters }}
      - {{ $exporter.Name }}
      {{- end }}

  telemetry:
    metrics:
      readers:
        - pull:
            exporter:
              prometheus:
                host: "{{ .SelfIpReference }}"
                port: 8888
