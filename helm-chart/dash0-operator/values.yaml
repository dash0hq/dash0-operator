# This file contains the default values for the Dash0 Kubernetes Operator Helm chart.
# Values can be overriden via --set or by providing additional yaml files when running helm install.

# settings for the operator/controller
operator:
  # number of replica for the controller manager deployment
  replicaCount: 1

  # settings for the service account to be used
  serviceAccount:
    # whether to create a dedicated service account, set this to false if you want to provide a separately
    # created service account
    create: true
    # can be used to override the default name of the serviceaccount (defaults to "dash0-operator-controller-manager")
    name: ""

  # common labels, will be added to all operator resources, example:
  # additionalLabels:
  #   label1: "value 1"
  #   label2: "value 2"
  additionalLabels: {}

  # additional annotations for the controller manager service, example
  # serviceAnnotations:
  #   annotation1: "value 1"
  #   annotation2: "value 2"
  serviceAnnotations: {}

  # additional annotations for the controller manager deployment, example:
  # deploymentAnnotations:
  #   annotation1: "value 1"
  #   annotation2: "value 2"
  deploymentAnnotations: {}

  # additional annotations for the controller manager pod(s), example:
  # podAnnotations:
  #   annotation1: "value 1"
  #   annotation2: "value 2"
  podAnnotations: {}

  # additional labels for the controller manager pod(s), example:
  # podLabels:
  #   label1: "value 1"
  #   label2: "value 2"
  podLabels: {}

  # resources for the controller manager pod(s)
  managerPodResources:
    limits:
      cpu: 500m
      memory: 128Mi
      ephemeral-storage: 500Mi
    requests:
      cpu: 10m
      memory: 64Mi
      ephemeral-storage: 500Mi

  # resources for the kube-rbac-proxy pod(s)
  kubeRbacProxyPodResources:
    limits:
      cpu: 500m
      memory: 128Mi
    requests:
      cpu: 5m
      memory: 64Mi

  # the port for the metrics service
  metricsPort: 8443

  # the port for the admission webhook service which instruments new workloads at deploy time
  webhookPort: 443

  # the container image to use for the controller manager component (there should usually be no reason to override this)
  image:
    # Use a different image entirely. Note that Dash0 does not offer support for Dash0 operator setups that do not use
    # Dash0's official image.
    repository: "ghcr.io/dash0hq/operator-controller"
    # overrides the image tag, which defaults to the chart appVersion
    tag:
    # pull image by digest instead of tag; if this is set, the tag value will be ignored
    digest:
    # override the default image pull policy
    pullPolicy:

  # the container image to use for the instrumentation init container
  # (there should usually be no reason to override this)
  initContainerImage:
    # Use a different image for the init container entirely. Note that Dash0 does not offer support for Dash0 operator
    # setups that do not use Dash0's official init container image.
    repository: "ghcr.io/dash0hq/instrumentation"
    # overrides the image tag, which defaults to the chart appVersion.
    tag:
    # pull image by digest instead of tag; if this is set, the tag value will be ignored
    digest:
    # override the default image pull policy
    pullPolicy:

  # the image pull secrets to pull the container images
  imagePullSecrets: [ ]

  # If set to true, instructs the logger (Zap) to use a Zap development config (stacktraces on warnings, no sampling),
  # otherwise a Zap production config will be used (stacktraces on errors, sampling).
  developmentMode: false

  # If set, the instrumented workloads will send telemetry data to this URL instead of the default URL for the
  # OpenTelemetry collector instance that this Helm chart deploys. This setting is meant to be used together with
  # the setting opentelemetry-collector.enabled: false. If opentelemetry-collector.enabled is not set to false, the
  # setting operator.openTelemetryCollectorBaseUrl should be left unset.
  openTelemetryCollectorBaseUrl:

  # If set to true, the operator Helm chart will skip the check for the Dash0 authorization secret. This should only
  # be done for testing purposes.
  disableSecretCheck: false

  # If set to true, the operator Helm chart will skip the check for the OTLP endpoing setting. This should only be done
  # for testing purposes.
  disableOtlpEndpointCheck: false

# settings for the OpenTelemetry collector instance that Dash0 will use for reporting data to Dash0
opentelemetry-collector:
  # Set this to false if you do not want the Dash0 Kubernetes operator helm chart to deploy an OpenTelemetry collector
  # daemonset. Note that if you disable this, you will need to provide your own OpenTelemetry collector instance
  # and also provide its URL via the setting operator.openTelemetryCollectorBaseUrl.
  enabled: true

  image:
    repository: otel/opentelemetry-collector-k8s

  mode: daemonset

  service:
    enabled: true

  presets:
    kubernetesAttributes:
      enabled: true
    # kubeletMetrics:
    #   enabled: true

  additionalLabels:
    dash0.com/enable: "false"

  resources:
    limits:
      memory: 500Mi

  extraVolumes:
    - name: dash0-secret-volume
      secret:
        secretName: dash0-authorization-secret
  extraVolumeMounts:
    - name: dash0-secret-volume
      readOnly: true
      mountPath: "/etc/dash0/secret-volume"

  config:
    extensions:
      bearertokenauth/dash0:
        scheme: "Bearer"
        filename: "/etc/dash0/secret-volume/dash0-authorization-token"

    receivers:
      # Removing these receivers by setting them to null will print three warnings in helm 3.13.3 (and probaly other
      # 3.13.x versions) during helm install. They can be ignored safely. Probably related to
      # https://github.com/helm/helm/issues/12441 - not sure why that one is closed, apparently it is not fixed.
      # coalesce.go:286: warning: cannot overwrite table with non table for dash0-operator.opentelemetry-collector.config.receivers.jaeger (map[protocols:map[grpc:map[endpoint:${env:MY_POD_IP}:14250] thrift_compact:map[endpoint:${env:MY_POD_IP}:6831] thrift_http:map[endpoint:${env:MY_POD_IP}:14268]]])
      # coalesce.go:286: warning: cannot overwrite table with non table for dash0-operator.opentelemetry-collector.config.receivers.prometheus (map[config:map[scrape_configs:[map[job_name:opentelemetry-collector scrape_interval:10s static_configs:[map[targets:[${env:MY_POD_IP}:8888]]]]]]])
      # coalesce.go:286: warning: cannot overwrite table with non table for dash0-operator.opentelemetry-collector.config.receivers.zipkin (map[endpoint:${env:MY_POD_IP}:9411])
      jaeger: null
      prometheus: null
      zipkin: null

    exporters:
      otlp:
        auth:
          authenticator: bearertokenauth/dash0
        # needs to be provided via --set or an additional values file
        endpoint:

    service:
      extensions:
        - health_check
        - memory_ballast
        - bearertokenauth/dash0

      pipelines:
        traces:
          receivers:
            - otlp
          processors:
            - k8sattributes
            - memory_limiter
            - batch
          exporters:
            - otlp
        metrics:
          receivers:
            - otlp
          processors:
            - k8sattributes
            - memory_limiter
            - batch
          exporters:
            - otlp
        logs:
          receivers:
            - otlp
          processors:
            - k8sattributes
            - memory_limiter
            - batch
          exporters:
            - otlp

  ports:
    jaeger-compact:
      enabled: false
    jaeger-thrift:
      enabled: false
    jaeger-grpc:
      enabled: false
    zipkin:
      enabled: false
