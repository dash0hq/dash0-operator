{{- /*
Helm does not have a way to share generated values between files. So, we do not have another way to generate a
self-signed cert and use it across deployment, webhook, service and CRDs (for conversion webhooks) other than putting
all these resources into the same template file.

See https://helm.sh/docs/howto/charts_tips_and_tricks/#automatically-roll-deployments:
> Each invocation of the template function will generate a unique random string. This means that if it's necessary to
> sync the random strings used by multiple resources, all relevant resources will need to be in the same template file.
*/ -}}
{{- $altNames := list ( printf "%s.%s.svc" (include "dash0-operator.webhookServiceName" . ) .Release.Namespace ) ( printf "%s-metrics.%s.svc" (include "dash0-operator.chartName" . ) .Release.Namespace ) -}}
{{- $ca := genCA "dash0-operator-ca" 365 -}}
{{- $cert := genSignedCert ( include "dash0-operator.chartName" . ) nil $altNames 365 $ca -}}
{{- /*
On upgrade, we want to avoid the webhook service from routing to an older pod, which will use a different certificate.
Therefore, we add a digest of the cert as a label of the controller pods, which we can use in service selector to ensure
routing to the newer controller pods.
*/ -}}
{{- $certFingerprint := $cert.Cert | b64enc | substr 10 25 | quote }}

{{- if not .Values.operator.certManager.useCertManager }}
{{/*
------
Secret
------
*/}}
---
apiVersion: v1
kind: Secret
type: kubernetes.io/tls
metadata:
  name: {{ include "dash0-operator.chartName" . }}-certificates
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/name: dash0-operator
    app.kubernetes.io/component: certificates
    app.kubernetes.io/instance: secret
data:
  ca.crt: {{ $ca.Cert | b64enc }}
  tls.crt: {{ $cert.Cert | b64enc }}
  tls.key: {{ $cert.Key | b64enc }}

{{- end }}{{/* closes "if not .Values.operator.certManager.useCertManager" */}}

{{/*
---------------------------
Operator Manager Deployment
---------------------------
*/}}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "dash0-operator.deploymentName" . }}
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/name: dash0-operator
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: deployment
    {{- include "dash0-operator.labels" . | nindent 4 }}
    dash0.com/enable: "false"
  {{- with .Values.operator.deploymentAnnotations }}
  annotations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
spec:
  replicas: {{ .Values.operator.replicaCount }}
  selector:
    matchLabels:
      app.kubernetes.io/name: dash0-operator
      app.kubernetes.io/component: controller
  template:
    metadata:
      annotations:
        kubectl.kubernetes.io/default-container: manager
        {{- if .Values.operator.podAnnotations }}
        {{- include "dash0-operator.podAnnotations" . | nindent 8 }}
        {{- end }}
      labels:
        app.kubernetes.io/name: dash0-operator
        app.kubernetes.io/component: controller
        {{- if not .Values.operator.certManager.useCertManager }}
        dash0.com/cert-digest: {{ $certFingerprint }}
        {{- end }}
        {{- if .Values.operator.podLabels }}
        {{- include "dash0-operator.podLabels" . | nindent 8 }}
        {{- end }}
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              {{- if not .Values.operator.gke.autopilot.enabled }}
              - key: "dash0.com/enable"
                operator: "NotIn"
                values: ["false"]
              {{- end }}
              - key: "kubernetes.io/os"
                operator: "In"
                values: ["linux"]
{{- if .Values.operator.tolerations }}
      tolerations:
        {{- toYaml .Values.operator.tolerations | nindent 8 }}
{{- end }}
{{- if .Values.operator.managerPriorityClassName }}
      priorityClassName: {{ .Values.operator.managerPriorityClassName }}
{{- end }}
      containers:
      - name: manager
        image: {{ include "dash0-operator.image" . | quote }}
        {{- if .Values.operator.image.pullPolicy }}
        imagePullPolicy: {{ .Values.operator.image.pullPolicy }}
        {{- end }}
        command:
        - /manager
        args:
        - --health-probe-bind-address=:8081
        - --metrics-bind-address=127.0.0.1:8080
        - --leader-elect
{{- if .Values.operator.dash0Export.enabled }}
{{- if not .Values.operator.dash0Export.endpoint }}
{{- fail "Error: operator.dash0Export.enabled is set to true, but you did not provide a value for operator.dash0Export.endpoint. Please refer to the installation instructions at https://github.com/dash0hq/dash0-operator/tree/main/helm-chart/dash0-operator." -}}
{{- end }}{{/* closes "not .Values.operator.dash0Export.endpoint" */}}
        - --operator-configuration-endpoint={{ .Values.operator.dash0Export.endpoint }}
{{- if .Values.operator.dash0Export.token }}
        - --operator-configuration-token={{ .Values.operator.dash0Export.token }}
{{- else if (and .Values.operator.dash0Export.secretRef.name .Values.operator.dash0Export.secretRef.key) }}
{{- if not .Values.operator.dash0Export.disableSecretValidation }}
{{- $secret := lookup "v1" "Secret" .Release.Namespace .Values.operator.dash0Export.secretRef.name -}}
{{- if $secret -}}
{{- if not (index $secret.data .Values.operator.dash0Export.secretRef.key) -}}
{{- fail (printf "Error: There is a secret named \"%s\" in the target namespace \"%s\", but it does not have the required key \"%s\". Please refer to the installation instructions at https://github.com/dash0hq/dash0-operator/tree/main/helm-chart/dash0-operator." .Values.operator.dash0Export.secretRef.name .Release.Namespace .Values.operator.dash0Export.secretRef.key) -}}
{{- end -}}{{/* closes "if not (index $secret.data .Values.operator.dash0Export.secretRef.key) -}}" */}}
{{- else -}}{{/* else for "if $secret" */}}
{{- fail (printf "Error: There is no secret named \"%s\" in the target namespace \"%s\". Please refer to the installation instructions at https://github.com/dash0hq/dash0-operator/tree/main/helm-chart/dash0-operator." .Values.operator.dash0Export.secretRef.name .Release.Namespace) -}}
{{- end }}{{/*closes "if $secret" */}}
{{- end }}{{/*closes "not .Values.operator.dash0Export.disableSecretValidation" */}}
        - --operator-configuration-secret-ref-name={{ .Values.operator.dash0Export.secretRef.name }}
        - --operator-configuration-secret-ref-key={{ .Values.operator.dash0Export.secretRef.key }}
{{- else }}{{/*else for "Values.operator.dash0Export.token" / "else if (and .Values.operator.dash0Export.secretRef.name .Values.operator.dash0Export.secretRef.key)" */}}
{{- fail "Error: operator.dash0Export.enabled is set to true, but neither operator.dash0Export.token nor operator.dash0Export.secretRef.name & operator.dash0Export.secretRef.key have been provided. Please refer to the installation instructions at https://github.com/dash0hq/dash0-operator/tree/main/helm-chart/dash0-operator." -}}
{{- end }}{{/*closes "if Values.operator.dash0Export.token" */}}
{{- if .Values.operator.dash0Export.apiEndpoint }}
        - --operator-configuration-api-endpoint={{ .Values.operator.dash0Export.apiEndpoint }}
{{- end }}{{/*closes "if .Values.operator.dash0Export.apiEndpoint" */}}
        - --operator-configuration-self-monitoring-enabled={{ .Values.operator.selfMonitoringEnabled }}
        - --operator-configuration-kubernetes-infrastructure-metrics-collection-enabled={{ .Values.operator.kubernetesInfrastructureMetricsCollectionEnabled }}
        - --operator-configuration-collect-pod-labels-and-annotations-enabled={{ .Values.operator.collectPodLabelsAndAnnotationsEnabled }}
{{- if .Values.operator.clusterName }}
        - --operator-configuration-cluster-name={{ .Values.operator.clusterName }}
{{- end }}{{/*closes "if .Values.operator.clusterName" */}}
{{- if .Values.operator.dash0Export.dataset }}
        - --operator-configuration-dataset={{ .Values.operator.dash0Export.dataset }}
{{- end }}{{/*closes "if .Values.operator.dash0Export.dataset" */}}
{{- end }}{{/*closes "if .Values.operator.dash0Export.enabled" */}}
        - --force-use-otel-collector-service-url={{ .Values.operator.collectors.forceUseServiceUrl }}
        - --gke-autopilot={{ .Values.operator.gke.autopilot.enabled }}
        - --disable-otel-collector-host-ports={{ .Values.operator.collectors.disableHostPorts }}
{{- if (default .Values.operator.instrumentation.delayAfterEachWorkloadMillis .Values.operator.instrumentationDelayAfterEachWorkloadMillis) }}
        - --instrumentation-delay-after-each-workload-millis={{ default .Values.operator.instrumentation.delayAfterEachWorkloadMillis .Values.operator.instrumentationDelayAfterEachWorkloadMillis }}
{{- end }}
{{- if (default .Values.operator.instrumentation.delayAfterEachNamespaceMillis .Values.operator.instrumentationDelayAfterEachNamespaceMillis) }}
        - --instrumentation-delay-after-each-namespace-millis={{ default .Values.operator.instrumentation.delayAfterEachNamespaceMillis .Values.operator.instrumentationDelayAfterEachNamespaceMillis }}
{{- end }}
        env:
        - name: DASH0_OPERATOR_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: DASH0_DEPLOYMENT_NAME
          value: {{ include "dash0-operator.deploymentName" . }}
        - name: DASH0_WEBHOOK_SERVICE_NAME
          value: {{ include "dash0-operator.webhookServiceName" . }}
        - name: OTEL_COLLECTOR_NAME_PREFIX
          value: {{ .Release.Name | quote }}
        - name: DASH0_OPERATOR_IMAGE
          value: {{ include "dash0-operator.image" . | quote }}
        - name: DASH0_INIT_CONTAINER_IMAGE
          value: {{ include "dash0-operator.initContainerImage" . | quote }}
        {{- if .Values.operator.initContainerImage.pullPolicy }}
        - name: DASH0_INIT_CONTAINER_IMAGE_PULL_POLICY
          value: {{ .Values.operator.initContainerImage.pullPolicy }}
        {{- end }}
        - name: DASH0_COLLECTOR_IMAGE
          value: {{ include "dash0-operator.collectorImage" . | quote }}
        {{- if .Values.operator.collectorImage.pullPolicy }}
        - name: DASH0_COLLECTOR_IMAGE_PULL_POLICY
          value: {{ .Values.operator.collectorImage.pullPolicy }}
        {{- end }}
        - name: DASH0_CONFIGURATION_RELOADER_IMAGE
          value: {{ include "dash0-operator.configurationReloaderImage" . | quote }}
        {{- if .Values.operator.configurationReloaderImage.pullPolicy }}
        - name: DASH0_CONFIGURATION_RELOADER_IMAGE_PULL_POLICY
          value: {{ .Values.operator.configurationReloaderImage.pullPolicy }}
        {{- end }}
        - name: DASH0_FILELOG_OFFSET_SYNC_IMAGE
          value: {{ include "dash0-operator.filelogOffsetSyncImage" . | quote }}
        {{- if .Values.operator.filelogOffsetSyncImage.pullPolicy }}
        - name: DASH0_FILELOG_OFFSET_SYNC_IMAGE_PULL_POLICY
          value: {{ .Values.operator.filelogOffsetSyncImage.pullPolicy }}
        {{- end }}
        - name: DASH0_FILELOG_OFFSET_VOLUME_OWNERSHIP_IMAGE
          value: {{ include "dash0-operator.filelogOffsetVolumeOwnershipImage" . | quote }}
        {{- if .Values.operator.filelogOffsetVolumeOwnershipImage.pullPolicy }}
        - name: DASH0_FILELOG_OFFSET_VOLUME_OWNERSHIP_IMAGE_PULL_POLICY
          value: {{ .Values.operator.filelogOffsetVolumeOwnershipImage.pullPolicy }}
        {{- end }}
        {{- if .Values.operator.developmentMode }}
        - name: DASH0_DEVELOPMENT_MODE
          value: {{ .Values.operator.developmentMode | toString | quote }}
        {{- end }}
        {{- if .Values.operator.instrumentation.debug }}
        - name: DASH0_INSTRUMENTATION_DEBUG
          value: {{ .Values.operator.instrumentation.debug  | toString | quote }}
        {{- end }}
        {{- if .Values.operator.collectors.debugVerbosityDetailed }}
        - name: OTEL_COLLECTOR_DEBUG_VERBOSITY_DETAILED
          value: {{ .Values.operator.collectors.debugVerbosityDetailed | toString | quote }}
        {{- end }}
        {{- if gt (int (.Values.operator.collectors.sendBatchMaxSize | default 0)) 0 }}
        - name: OTEL_COLLECTOR_SEND_BATCH_MAX_SIZE
          value: {{ .Values.operator.collectors.sendBatchMaxSize | quote }}
        {{- end }}
        - name: K8S_POD_UID
          valueFrom:
            fieldRef:
              fieldPath: metadata.uid
        - name: K8S_NODE_IP
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        - name: K8S_NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: K8S_POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: K8S_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        ports:
        - containerPort: 9443
          name: webhook-server
          protocol: TCP
        resources:
          {{- toYaml .Values.operator.managerContainerResources | nindent 10 }}
        {{ include "dash0-operator.restrictiveContainerSecurityContext" dict | nindent 8 }}
        volumeMounts:
        - name: certificates
          mountPath: /tmp/k8s-webhook-server/serving-certs
          readOnly: true
        - name: config-volume
          mountPath: /etc/config
          readOnly: true
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8081
          initialDelaySeconds: 15
          periodSeconds: 20
        readinessProbe:
          httpGet:
            path: /readyz
            port: 8081
          initialDelaySeconds: 5
          periodSeconds: 5
      - name: kube-rbac-proxy
        image: {{ include "dash0-operator.kubeRbacProxyImage" . | quote }}
        args:
        - --secure-listen-address=0.0.0.0:8443
        - --upstream=http://127.0.0.1:8080/
        - --logtostderr=true
        - --v=0
        ports:
        - containerPort: 8443
          name: https
          protocol: TCP
        resources:
          {{- toYaml .Values.operator.kubeRbacProxyContainerResources | nindent 10 }}
        {{ include "dash0-operator.restrictiveContainerSecurityContext" (dict "userId" 65532) | nindent 8 }}
      {{- with .Values.operator.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{ include "dash0-operator.restrictivePodSecurityContext" dict | nindent 6 }}
      serviceAccountName: {{ template "dash0-operator.serviceAccountName" . }}
      automountServiceAccountToken: true
      terminationGracePeriodSeconds: 10
      volumes:
      - name: certificates
        secret:
          defaultMode: 420
          {{- if not .Values.operator.certManager.useCertManager }}
          secretName: {{ include "dash0-operator.chartName" . }}-certificates
          {{- else }}
          {{- if not .Values.operator.certManager.secretName }}
          {{- fail "Error: operator.certManager.useCertManager is set to true, but you did not provide a value for operator.certManager.secretName. Please refer to the instructions at https://github.com/dash0hq/dash0-operator/tree/main/helm-chart/dash0-operator#using-cert-manager." -}}
          {{- end }}
          secretName: {{ .Values.operator.certManager.secretName | quote }}
          {{- end }}
      - name: config-volume
        configMap:
          name: {{ template "dash0-operator.extraConfigMapName" . }}

{{/*
---------------
Webhook Service
---------------
*/}}
---
apiVersion: v1
kind: Service
metadata:
  name: {{ include "dash0-operator.webhookServiceName" . }}
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/name: dash0-operator
    app.kubernetes.io/component: webhook-service
    app.kubernetes.io/instance: webhook-service
    {{- include "dash0-operator.labels" . | nindent 4 }}
spec:
  ports:
  - port: {{ template "dash0-operator.webhookServicePort" . }}
    protocol: TCP
    targetPort: 9443
  selector:
    app.kubernetes.io/name: dash0-operator
    app.kubernetes.io/component: controller
    {{- if not .Values.operator.certManager.useCertManager }}
    dash0.com/cert-digest: {{ $certFingerprint }}
    {{- end }}

{{/*
----------------------
Webhook Configurations
----------------------
*/}}
---
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  name: {{ template "dash0-operator.chartName" . }}-injector
  labels:
    app.kubernetes.io/name: dash0-operator
    app.kubernetes.io/component: injector
    app.kubernetes.io/instance: mutating-webhook
    {{- include "dash0-operator.labels" . | nindent 4 }}
  {{- if .Values.operator.certManager.useCertManager }}
  {{- if empty .Values.operator.certManager.certManagerAnnotations }}
  {{- fail "Error: operator.certManager.useCertManager is set to true, but you did not provide any annotations in operator.certManager.certManagerAnnotations. Please refer to the instructions at https://github.com/dash0hq/dash0-operator/tree/main/helm-chart/dash0-operator#using-cert-manager." -}}
  {{- end }}
  {{- with .Values.operator.certManager.certManagerAnnotations }}
  annotations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
  {{- end }}
webhooks:
- name: inject.dash0.com
  admissionReviewVersions:
  - v1
  namespaceSelector:
    matchExpressions:
      - key: kubernetes.io/metadata.name
        operator: NotIn
        values:
          - kube-system
          - kube-node-lease
      {{- if .Values.operator.gke.autopilot.enabled }}
      - key: kubernetes.io/metadata.name
        operator: NotIn
        values:
          - kube-system
          - gke-gmp-system
          - gke-managed-cim
          - gke-managed-volumepopulator
          - gke-managed-checkpointing
          - gke-managed-parallelstorecsi
          - gke-managed-lustrecsi
      {{- end }}
  clientConfig:
    {{- if not .Values.operator.certManager.useCertManager }}
    caBundle: {{ default "" ( $ca.Cert | b64enc ) }}
    {{- end }}
    service:
      name: {{ template "dash0-operator.webhookServiceName" . }}
      namespace: {{ .Release.Namespace }}
      port: {{ template "dash0-operator.webhookServicePort" . }}
      path: /workloads/inject
  failurePolicy: Ignore
  rules:
  - apiGroups:
    - apps
    apiVersions:
    - v1
    operations:
    - CREATE
    - UPDATE
    resources:
    - daemonsets
    - deployments
    - replicasets
    - statefulsets
    scope: Namespaced
  - apiGroups:
    - batch
    apiVersions:
    - v1
    operations:
    - CREATE
    - UPDATE
    resources:
    - cronjobs
  - apiGroups:
      - batch
    apiVersions:
      - v1
    operations:
      # do not listen to UPDATE for jobs, we cannot revert instrumentation or do anything on UPDATE requests, since jobs
      # are immutable
      - CREATE
    resources:
      - jobs
    scope: Namespaced
  - apiGroups: [""]
    apiVersions:
    - v1
    operations:
      # do not listen to UPDATE for pods, we cannot revert instrumentation or do anything on UPDATE requests, since pods
      # are effectively immutable (we cannot restart ownerless pods)
      - CREATE
    resources:
    - pods
    scope: Namespaced
  sideEffects: None
  timeoutSeconds: 5
---
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  name: {{ template "dash0-operator.chartName" . }}-operator-configuration-mutating
  labels:
    app.kubernetes.io/name: dash0-operator
    app.kubernetes.io/component: validator
    app.kubernetes.io/instance: operator-configuration-mutating-webhook
    {{- include "dash0-operator.labels" . | nindent 4 }}
  {{- if .Values.operator.certManager.useCertManager }}
  {{- with .Values.operator.certManager.certManagerAnnotations }}
  annotations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
  {{- end }}
webhooks:
  - name: mutate-operator-configuration.dash0.com
    clientConfig:
      {{- if not .Values.operator.certManager.useCertManager }}
      caBundle: {{ default "" ( $ca.Cert | b64enc ) }}
      {{- end }}
      service:
        name: {{ template "dash0-operator.webhookServiceName" . }}
        namespace: {{ .Release.Namespace }}
        port: {{ template "dash0-operator.webhookServicePort" . }}
        path: /operator-configuration/mutate
    admissionReviewVersions:
      - v1
    {{- if .Values.operator.gke.autopilot.enabled }}
    namespaceSelector:
      matchExpressions:
        - key: kubernetes.io/metadata.name
          operator: NotIn
          values:
            - kube-system
            - gke-gmp-system
            - gke-managed-cim
            - gke-managed-volumepopulator
            - gke-managed-checkpointing
            - gke-managed-parallelstorecsi
            - gke-managed-lustrecsi
    {{- end }}
    rules:
      - apiGroups:
          - operator.dash0.com
        apiVersions:
          - v1alpha1
        operations:
          - CREATE
          - UPDATE
        resources:
          - dash0operatorconfigurations
        scope: Cluster
    sideEffects: None
    timeoutSeconds: 5
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  name: {{ template "dash0-operator.chartName" . }}-operator-configuration-validator
  labels:
    app.kubernetes.io/name: dash0-operator
    app.kubernetes.io/component: validator
    app.kubernetes.io/instance: operator-configuration-validator-webhook
    {{- include "dash0-operator.labels" . | nindent 4 }}
  {{- if .Values.operator.certManager.useCertManager }}
  {{- with .Values.operator.certManager.certManagerAnnotations }}
  annotations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
  {{- end }}
webhooks:
  - name: validate-operator-configuration.dash0.com
    clientConfig:
      {{- if not .Values.operator.certManager.useCertManager }}
      caBundle: {{ default "" ( $ca.Cert | b64enc ) }}
      {{- end }}
      service:
        name: {{ template "dash0-operator.webhookServiceName" . }}
        namespace: {{ .Release.Namespace }}
        port: {{ template "dash0-operator.webhookServicePort" . }}
        path: /operator-configuration/validate
    admissionReviewVersions:
      - v1
    rules:
      - apiGroups:
          - operator.dash0.com
        apiVersions:
          - v1alpha1
        operations:
          - CREATE
          - UPDATE
        resources:
          - dash0operatorconfigurations
        scope: Cluster
    sideEffects: None
    timeoutSeconds: 5
---
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  name: {{ template "dash0-operator.chartName" . }}-monitoring-mutating
  labels:
    app.kubernetes.io/name: dash0-operator
    app.kubernetes.io/component: validator
    app.kubernetes.io/instance: monitoring-mutating-webhook
    {{- include "dash0-operator.labels" . | nindent 4 }}
  {{- if .Values.operator.certManager.useCertManager }}
  {{- with .Values.operator.certManager.certManagerAnnotations }}
  annotations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
  {{- end }}
webhooks:
  - name: mutate-monitoring.dash0.com
    clientConfig:
      {{- if not .Values.operator.certManager.useCertManager }}
      caBundle: {{ default "" ( $ca.Cert | b64enc ) }}
      {{- end }}
      service:
        name: {{ template "dash0-operator.webhookServiceName" . }}
        namespace: {{ .Release.Namespace }}
        port: {{ template "dash0-operator.webhookServicePort" . }}
        path: /monitoring/mutate
    admissionReviewVersions:
      - v1
    {{- if .Values.operator.gke.autopilot.enabled }}
    namespaceSelector:
      matchExpressions:
        - key: kubernetes.io/metadata.name
          operator: NotIn
          values:
            - kube-system
            - gke-gmp-system
            - gke-managed-cim
            - gke-managed-volumepopulator
            - gke-managed-checkpointing
            - gke-managed-parallelstorecsi
            - gke-managed-lustrecsi
    {{- end }}
    rules:
      - apiGroups:
          - operator.dash0.com
        apiVersions:
          - v1beta1
        operations:
          - CREATE
          - UPDATE
        resources:
          - dash0monitorings
        scope: Namespaced
    sideEffects: None
    timeoutSeconds: 5
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  name: {{ template "dash0-operator.chartName" . }}-monitoring-validator
  labels:
    app.kubernetes.io/name: dash0-operator
    app.kubernetes.io/component: validator
    app.kubernetes.io/instance: monitoring-validator-webhook
    {{- include "dash0-operator.labels" . | nindent 4 }}
  {{- if .Values.operator.certManager.useCertManager }}
  {{- with .Values.operator.certManager.certManagerAnnotations }}
  annotations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
  {{- end }}
webhooks:
  - name: validate-monitoring.dash0.com
    clientConfig:
       {{- if not .Values.operator.certManager.useCertManager }}
      caBundle: {{ default "" ( $ca.Cert | b64enc ) }}
      {{- end }}
      service:
        name: {{ template "dash0-operator.webhookServiceName" . }}
        namespace: {{ .Release.Namespace }}
        port: {{ template "dash0-operator.webhookServicePort" . }}
        path: /monitoring/validate
    admissionReviewVersions:
      - v1
    rules:
      - apiGroups:
          - operator.dash0.com
        apiVersions:
          - v1beta1
        operations:
          - CREATE
          - UPDATE
        resources:
          - dash0monitorings
        scope: Namespaced
    sideEffects: None
    timeoutSeconds: 5

{{/*
---------------
Metrics Service
---------------
*/}}
---
apiVersion: v1
kind: Service
metadata:
  name: {{ include "dash0-operator.chartName" . }}-metrics
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/name: dash0-operator
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: metrics-service
    {{- include "dash0-operator.labels" . | nindent 4 }}
  {{- with .Values.operator.serviceAnnotations }}
  annotations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
spec:
  ports:
  - name: https
    port: {{ .Values.operator.metricsPort }}
    protocol: TCP
    targetPort: https
  selector:
    app.kubernetes.io/name: dash0-operator
    app.kubernetes.io/component: controller
    {{- if not .Values.operator.certManager.useCertManager }}
    dash0.com/cert-digest: {{ $certFingerprint }}
    {{- end }}

{{/*
-------------------------------------------
Custom Resource Definition: Dash0Monitoring
-------------------------------------------
*/}}
---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    controller-gen.kubebuilder.io/version: v0.19.0
    {{- if .Values.operator.certManager.useCertManager }}
    {{- with .Values.operator.certManager.certManagerAnnotations }}
      {{- toYaml . | nindent 4 }}
    {{- end }}
    {{- end }}
  name: dash0monitorings.operator.dash0.com
spec:
  group: operator.dash0.com
  names:
    kind: Dash0Monitoring
    listKind: Dash0MonitoringList
    plural: dash0monitorings
    singular: dash0monitoring
  scope: Namespaced
  versions:
  - name: v1alpha1
    schema:
      openAPIV3Schema:
        description: Dash0Monitoring is the schema for the Dash0Monitoring API
        properties:
          apiVersion:
            description: |-
              APIVersion defines the versioned schema of this representation of an object.
              Servers should convert recognized schemas to the latest internal value, and
              may reject unrecognized values.
              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
            type: string
          kind:
            description: |-
              Kind is a string value representing the REST resource this object represents.
              Servers may infer this from the endpoint the client submits requests to.
              Cannot be updated.
              In CamelCase.
              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
            type: string
          metadata:
            type: object
          spec:
            description: |-
              Dash0MonitoringSpec describes the details of monitoring a single Kubernetes namespace with Dash0 and sending
              telemetry to an observability backend.
            properties:
              __dash0_internal__normalizedTransform:
                description: Only used internally, this field must not be specified
                  by users.
                properties:
                  error_mode:
                    description: |-
                      FilterTransformErrorMode determine how the filter or the transform processor reacts to errors that occur while
                      processing a condition.
                    enum:
                    - ignore
                    - silent
                    - propagate
                    type: string
                  log_statements:
                    items:
                      properties:
                        conditions:
                          items:
                            type: string
                          type: array
                        context:
                          type: string
                        error_mode:
                          description: |-
                            FilterTransformErrorMode determine how the filter or the transform processor reacts to errors that occur while
                            processing a condition.
                          enum:
                          - ignore
                          - silent
                          - propagate
                          type: string
                        statements:
                          items:
                            type: string
                          type: array
                      type: object
                    type: array
                  metric_statements:
                    items:
                      properties:
                        conditions:
                          items:
                            type: string
                          type: array
                        context:
                          type: string
                        error_mode:
                          description: |-
                            FilterTransformErrorMode determine how the filter or the transform processor reacts to errors that occur while
                            processing a condition.
                          enum:
                          - ignore
                          - silent
                          - propagate
                          type: string
                        statements:
                          items:
                            type: string
                          type: array
                      type: object
                    type: array
                  trace_statements:
                    items:
                      properties:
                        conditions:
                          items:
                            type: string
                          type: array
                        context:
                          type: string
                        error_mode:
                          description: |-
                            FilterTransformErrorMode determine how the filter or the transform processor reacts to errors that occur while
                            processing a condition.
                          enum:
                          - ignore
                          - silent
                          - propagate
                          type: string
                        statements:
                          items:
                            type: string
                          type: array
                      type: object
                    type: array
                type: object
              export:
                description: |-
                  The configuration of the observability backend to which telemetry data will be sent. This property is optional.
                  If not set, the operator will use the default export configuration from the cluster-wide
                  Dash0OperatorConfiguration resource, if present. If no Dash0OperatorConfiguration resource has been created for
                  the cluster, or if the Dash0OperatorConfiguration resource does not have at least one export defined, creating a
                  Dash0Monitoring resource without export settings will result in an error.

                  The export can either be Dash0 or another OTLP-compatible backend. You can also combine up to three exporters
                  (i.e. Dash0 plus gRPC plus HTTP). This allows sending the same data to two or three targets simultaneously. When
                  the export setting is present, it has to contain at least one exporter.
                minProperties: 1
                properties:
                  dash0:
                    description: The configuration of the Dash0 ingress endpoint to
                      which telemetry data will be sent.
                    properties:
                      apiEndpoint:
                        description: |-
                          The base URL of the Dash0 API to talk to. This is not where telemetry will be sent, but it is used for managing
                          dashboards, check rules, synthetic checks and views via the operator. This property is optional. The value
                          needs to be the API endpoint of your Dash0 organization. The correct API endpoint can be copied fom
                          https://app.dash0.com -> organization settings -> "Endpoints" -> "API". The correct endpoint value will always
                          start with "https://api." and end in ".dash0.com"
                        type: string
                      authorization:
                        description: Mandatory authorization settings for sending
                          data to Dash0.
                        maxProperties: 1
                        minProperties: 1
                        properties:
                          secretRef:
                            description: |-
                              A reference to a Kubernetes secret containing the Dash0 authorization token. This property is optional, and is
                              ignored if the token property is set. The authorization token for your Dash0 organization can be copied from
                              https://app.dash0.com -> organization settings -> "Auth Tokens".
                            properties:
                              key:
                                default: token
                                description: The key of the value which contains the
                                  Dash0 authorization token. Defaults to "token"
                                type: string
                              name:
                                default: dash0-authorization-secret
                                description: The name of the secret containing the
                                  Dash0 authorization token. Defaults to "dash0-authorization-secret".
                                type: string
                            required:
                            - key
                            - name
                            type: object
                          token:
                            description: |-
                              The Dash0 authorization token. This property is optional, but either this property or the SecretRef property has
                              to be provided. If both are provided, the token will be used and SecretRef will be ignored. The authorization
                              token for your Dash0 organization can be copied from https://app.dash0.com -> organization settings ->
                              "Auth Tokens".
                            type: string
                        type: object
                      dataset:
                        default: default
                        description: |-
                          The name of the Dash0 dataset to which telemetry data will be sent. This property is optional. If omitted, the
                          dataset "default" will be used.
                        type: string
                      endpoint:
                        description: |-
                          The URL of the Dash0 ingress endpoint to which telemetry data will be sent. This property is mandatory. The value
                          needs to be the OTLP/gRPC endpoint of your Dash0 organization. The correct OTLP/gRPC endpoint can be copied fom
                          https://app.dash0.com -> organization settings -> "Endpoints". The correct endpoint value will always start with
                          `ingress.` and end in `dash0.com:4317`.
                        minLength: 1
                        type: string
                    required:
                    - authorization
                    - endpoint
                    type: object
                  grpc:
                    description: The settings for an exporter to send telemetry to
                      an arbitrary OTLP-compatible receiver via gRPC.
                    properties:
                      endpoint:
                        description: The URL of the OTLP-compatible receiver to which
                          telemetry data will be sent. This property is mandatory.
                        type: string
                      headers:
                        description: Additional headers to be sent with each gRPC
                          request, for example for authorization. This property is
                          optional.
                        items:
                          properties:
                            name:
                              type: string
                            value:
                              type: string
                          required:
                          - name
                          - value
                          type: object
                        type: array
                      insecure:
                        description: Explicitly defines whether TLS is used. Per default,
                          a secure connection is assumed, unless the endpoint starts
                          with 'http://'.
                        type: boolean
                      insecureSkipVerify:
                        description: |-
                          Whether to skip verifying the server's certificate chain. It is a validation error to explicitly set
                          `insecure=true` and `insecureSkipVerify=true` at the same time, since `insecure` means TLS won't be used at all.
                        type: boolean
                    required:
                    - endpoint
                    type: object
                  http:
                    description: The settings for an exporter to send telemetry to
                      an arbitrary OTLP-compatible receiver via HTTP.
                    properties:
                      encoding:
                        default: proto
                        description: The encoding of the OTLP data when sent via HTTP.
                          Can be either proto or json, defaults to proto.
                        enum:
                        - proto
                        - json
                        type: string
                      endpoint:
                        description: The URL of the OTLP-compatible receiver to which
                          telemetry data will be sent. This property is mandatory.
                        type: string
                      headers:
                        description: Additional headers to be sent with each HTTP
                          request, for example for authorization. This property is
                          optional.
                        items:
                          properties:
                            name:
                              type: string
                            value:
                              type: string
                          required:
                          - name
                          - value
                          type: object
                        type: array
                      insecureSkipVerify:
                        description: Whether verification of TLS certificates should
                          be skipped. Ignored when the endpoint uses an insecure connection.
                        type: boolean
                    required:
                    - endpoint
                    type: object
                type: object
              filter:
                description: |-
                  Optional filters for telemetry data that is collected in this namespace. This can be used to drop entire spans,
                  span events, metrics, metric data points, or log records. See "Transform" for advanced transformations (e.g.
                  removing span attributes, metric data point attributes, log record attributes etc.). This setting is optional,
                  by default, no filters are applied. It is a validation error to set `telemetryCollection.enabled=false` in the
                  operator configuration resource and set filters in any monitoring resource at the same time.
                properties:
                  error_mode:
                    default: ignore
                    description: |-
                      An optional field which will determine how the filter processor reacts to errors that occur while processing a
                      condition. Possible values:
                      - ignore: ignore errors returned by conditions, log them, continue with to the next condition.
                                This is the recommended mode and also the default mode if this property is omitted.
                      - silent: ignore errors returned by conditions, do not log them, continue with to the next condition.
                      - propagate: return the error up the processing pipeline. This will result in the payload being dropped from the
                                collector. Not recommended.

                      This is optional, default to "ignore", there is usually no reason to change this.

                      Note that although this can be specified per namespace, the filter conditions will be aggregated into one
                      single filter processor in the resulting OpenTelemetry collector configuration; if different error modes are
                      specified in different namespaces, the "most severe" error mode will be used (propagate > ignore > silent).
                    enum:
                    - ignore
                    - silent
                    - propagate
                    type: string
                  logs:
                    description: |-
                      Filters for the logs signal.
                      This can be used to drop _log records_.
                    properties:
                      log_records:
                        description: |-
                          A list of conditions for filtering log records.
                          This is a list of OTTL conditions.
                          All log records where at least one condition evaluates to true will be dropped.
                          (That is, the conditions are implicitly connected by a logical OR.)
                          Example:
                          - 'IsMatch(body, ".*password.*")'
                          - 'severity_number < SEVERITY_NUMBER_WARN'
                        items:
                          type: string
                        type: array
                    type: object
                  metrics:
                    description: |-
                      Filters for the metrics signal.
                      This can be used to drop entire _metrics_, or individual _data points_.
                    properties:
                      datapoint:
                        description: |-
                          A list of conditions for filtering metrics data points.
                          This is a list of OTTL conditions.
                          All data points where at least one condition evaluates to true will be dropped.
                          (That is, the conditions are implicitly connected by a logical OR.)
                          Note: If all datapoints for a metric are dropped, the metric will also be dropped.
                          Example:
                          - 'metric.name == "a.noisy.metric.with.many.datapoints" and value_int == 0' # filter metrics by value
                          - 'resource.attributes["service.name"] == "my_service_name"' # filter data points by resource attributes
                        items:
                          type: string
                        type: array
                      metric:
                        description: |-
                          A list of conditions for filtering metrics.
                          This is a list of OTTL conditions.
                          All metrics where at least one condition evaluates to true will be dropped.
                          (That is, the conditions are implicitly connected by a logical OR.)
                          Example:
                          - 'name == "k8s.replicaset.available"'
                          - 'name == "k8s.replicaset.desired"'
                          - 'type == METRIC_DATA_TYPE_HISTOGRAM'
                        items:
                          type: string
                        type: array
                    type: object
                  traces:
                    description: |-
                      Filters for the traces signal.
                      This can be used to drop _spans_ or _span events_.
                    properties:
                      span:
                        description: |-
                          A list of conditions for filtering spans.
                          This is a list of OTTL conditions.
                          All spans where at least one condition evaluates to true will be dropped.
                          (That is, the conditions are implicitly connected by a logical OR.)
                          Example:
                          - 'attributes["http.route"] == "/ready"'
                          - 'attributes["http.route"] == "/metrics"'
                        items:
                          type: string
                        type: array
                      spanevent:
                        description: |-
                          A list of conditions for filtering span events.
                          This is a list of OTTL conditions.
                          All span events where at least one condition evaluates to true will be dropped.
                          (That is, the conditions are implicitly connected by a logical OR.)
                          If all span events for a span are dropped, the span will be left intact.
                        items:
                          type: string
                        type: array
                    type: object
                type: object
              instrumentWorkloads:
                description: |-
                  Opt-out for automatic workload instrumentation for the target namespace. There are three possible settings:
                  `all`, `created-and-updated` and `none`. By default, the setting `all` is assumed, unless there is an operator
                  configuration resource with `telemetryCollection.enabled=false`, then the setting `none` is assumed.

                  If set to `all`, the operator will:
                  * automatically instrument existing workloads in the target namespace (i.e. workloads already running in the
                    namespace) when the Dash0 monitoring resource is deployed,
                  * instrument existing workloads or update the instrumentation of already instrumented workloads in the target
                    namespace when the Dash0 operator is first started or restarted (for example when updating the operator),
                  * instrument new workloads in the target namespace when they are deployed, and
                  * instrument changed workloads in the target namespace when changes are applied to them.
                  Note that the first two actions (instrumenting existing workloads) will result in restarting the pods of the
                  affected workloads.

                  If set to `created-and-updated`, the operator will not instrument existing workloads in the target namespace.
                  Instead, it will only:
                  * instrument new workloads in the target namespace when they are deployed, and
                  * instrument changed workloads in the target namespace when changes are applied to them.
                  This setting is useful if you want to avoid pod restarts as a side effect of deploying the Dash0 monitoring
                  resource or restarting the Dash0 operator.

                  You can opt out of automatically instrumenting workloads entirely by setting this option to `none`. With
                  `instrumentWorkloads: none`, workloads in the target namespace will never be instrumented to send telemetry to
                  Dash0.

                  If this setting is omitted, the value `all` is assumed and new, updated as well as existing Kubernetes workloads
                  will be automatically intrumented by the operator to send telemetry to Dash0, as described above. There is one
                  exception to this rule: If there is an operator configuration resource with `telemetryCollection.enabled=false`,
                  then the default setting is `none` instead of `all`, and no workloads will be instrumented by the Dash0 operator.

                  It is a validation error to set `telemetryCollection.enabled=false` in the operator configuration resource and
                  `instrumentWorkloadsMode=all` or `instrumentWorkloadsMode=created-and-updated` in any monitoring resource at the
                  same time.

                  More fine-grained per-workload control over instrumentation is available by setting the label
                  dash0.com/enable=false on individual workloads.
                enum:
                - all
                - created-and-updated
                - none
                type: string
              logCollection:
                description: |-
                  Settings for log collection in the target namespace. This setting is optional, by default the operator will
                  collect pod logs in the target namespace; unless there is an operator configuration resource with
                  `telemetryCollection.enabled=false`, then log collection is off by default. It is a validation error to set
                  `telemetryCollection.enabled=false` in the operator configuration resource and `logCollection.enabled=true` in any
                  monitoring resource at the same time.
                properties:
                  enabled:
                    description: |-
                      Opt-out for log collection for the target namespace. If set to `false`, the operator will not collect pod logs
                      in the target namespace and send the resulting log records to Dash0.

                      This setting is optional, it defaults to `true`, that is, if this setting is omitted, the value `true` is assumed
                      and the operator will collect pod logs in the target namespace; unless there is an operator configuration
                      resource with `telemetryCollection.enabled=false`, then log collection is off by default. It is a validation error
                      to set `telemetryCollection.enabled=false` in the operator configuration resource and
                      `logCollection.enabled=true` in any monitoring resource at the same time.
                    type: boolean
                type: object
              prometheusScraping:
                description: |-
                  Settings for scraping Prometheus metrics from pods in the target namespace according to their
                  prometheus.io/scrape annotations. This setting is optional, by default the operator will scrape metrics from pods
                  with these notations in the target namespace; unless there is an operator configuration resource with
                  `telemetryCollection.enabled=false`, then Prometheus scraping is off by default. It is a validation error to set
                  `telemetryCollection.enabled=false` in the operator configuration resource and `prometheusScraping.enabled=true`
                  in any monitoring resource at the same time.
                properties:
                  enabled:
                    description: |-
                      If enabled, the operator will configure its OpenTelemetry collector to scrape metrics from pods in the namespace
                      of this Dash0Monitoring resource according to their prometheus.io/scrape annotations via the OpenTelemetry
                      Prometheus receiver. This setting is optional, it defaults to `true`; unless there is an operator configuration
                      resource with `telemetryCollection.enabled=false`, then Prometheus scraping is off by default. It is a validation
                      error to set `telemetryCollection.enabled=false` in the operator configuration resource and
                      `prometheusScraping.enabled=true` in any monitoring resource at the same time.
                    type: boolean
                type: object
              prometheusScrapingEnabled:
                description: |-
                  Deprecated: This setting is deprecated. Please use
                      prometheusScraping:
                        enabled: false
                  instead of
                      prometheusScrapingEnabled: false

                  If enabled, the operator will configure its OpenTelemetry collector to scrape metrics from pods in the namespace
                  of this Dash0Monitoring resource according to their prometheus.io/scrape annotations via the OpenTelemetry
                  Prometheus receiver. This setting is optional, it defaults to `true`; unless there is an operator configuration
                  resource with `telemetryCollection.enabled=false`, then it defaults to `false`. It is a validation error to set
                  `telemetryCollection.enabled=false` in the operator configuration resource and `prometheusScrapingEnabled=true`
                  in any monitoring resource at the same time.
                type: boolean
              synchronizePersesDashboards:
                default: true
                description: |-
                  If enabled, the operator will watch Perses dashboard resources in this namespace and create corresponding
                  dashboards in Dash0 via the Dash0 API.
                  See https://github.com/dash0hq/dash0-operator/blob/main/helm-chart/dash0-operator/README.md#managing-dash0-dashboards-with-the-operator
                  for details. This setting is optional, it defaults to `true`.
                type: boolean
              synchronizePrometheusRules:
                default: true
                description: |-
                  If enabled, the operator will watch Prometheus rule resources in this namespace and create corresponding check
                  rules in Dash0 via the Dash0 API.
                  See https://github.com/dash0hq/dash0-operator/blob/main/helm-chart/dash0-operator/README.md#managing-dash0-check-rules-with-the-operator
                  for details. This setting is optional, it defaults to `true`.
                type: boolean
              transform:
                description: |-
                  Optional custom transformations for telemetry data that is collected in this namespace. This can be used to
                  remove span attributes, metric data point attributes, log record attributes etc. See "Filter" for basic filters
                  that can be used to drop entire spans, span events, metrics, metric data points, or log records.

                  For each signal type (traces, metrics, logs), a list of OTTL statements can be defined. These will be applied to
                  the telemetry collected in the namespace, following the order specified in the configuration. Each statement can
                  access and transform telemetry using OTTL functions.
                  See https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/transformprocessor
                  for details and examples. Note that this configuration currently supports the
                  [basic config style](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/transformprocessor/README.md#basic-config)
                  of the transform processor. The
                  [advanced config style](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/transformprocessor/README.md#advanced-config)
                  is not supported.

                  This setting is optional, by default, no transformations are applied. It is a validation error to set
                  `telemetryCollection.enabled=false` in the operator configuration resource and set transforms in any monitoring
                  resource at the same time.
                properties:
                  error_mode:
                    default: ignore
                    description: |-
                      An optional field which will determine how the transform processor reacts to errors that occur while processing a
                      statement. Possible values:
                      - ignore: ignore errors returned by statements, log them, continue with to the next statement.
                      - silent: ignore errors returned by statements, do not log them, continue with to the next statement.
                      - propagate: return the error up the processing pipeline. This will result in the payload being dropped from the
                        collector.

                      This is optional, default to "ignore".

                      Note that although this can be specified per namespace, the transform statements will be aggregated into one
                      single transform processor in the resulting OpenTelemetry collector configuration; if different error modes are
                      specified in different namespaces, the "most severe" error mode will be used (propagate > ignore > silent).
                    enum:
                    - ignore
                    - silent
                    - propagate
                    type: string
                  log_statements:
                    description: Transform statements (or groups) for the log signal
                      type.
                    x-kubernetes-preserve-unknown-fields: true
                  metric_statements:
                    description: Transform statements (or groups) for the metric signal
                      type.
                    x-kubernetes-preserve-unknown-fields: true
                  trace_statements:
                    description: Transform statements (or groups) for the trace signal
                      type.
                    x-kubernetes-preserve-unknown-fields: true
                type: object
            type: object
          status:
            description: Dash0MonitoringStatus defines the observed state of the Dash0Monitoring
              monitoring resource.
            properties:
              conditions:
                items:
                  description: "Condition contains details for one aspect of the current
                    state of this API Resource.\n---\nThis struct is intended for
                    direct use as an array at the field path .status.conditions.  For
                    example,\n\n\n\ttype FooStatus struct{\n\t    // Represents the
                    observations of a foo's current state.\n\t    // Known .status.conditions.type
                    are: \"Available\", \"Progressing\", and \"Degraded\"\n\t    //
                    +patchMergeKey=type\n\t    // +patchStrategy=merge\n\t    // +listType=map\n\t
                    \   // +listMapKey=type\n\t    Conditions []metav1.Condition `json:\"conditions,omitempty\"
                    patchStrategy:\"merge\" patchMergeKey:\"type\" protobuf:\"bytes,1,rep,name=conditions\"`\n\n\n\t
                    \   // other fields\n\t}"
                  properties:
                    lastTransitionTime:
                      description: |-
                        lastTransitionTime is the last time the condition transitioned from one status to another.
                        This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
                      format: date-time
                      type: string
                    message:
                      description: |-
                        message is a human readable message indicating details about the transition.
                        This may be an empty string.
                      maxLength: 32768
                      type: string
                    observedGeneration:
                      description: |-
                        observedGeneration represents the .metadata.generation that the condition was set based upon.
                        For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date
                        with respect to the current state of the instance.
                      format: int64
                      minimum: 0
                      type: integer
                    reason:
                      description: |-
                        reason contains a programmatic identifier indicating the reason for the condition's last transition.
                        Producers of specific condition types may define expected values and meanings for this field,
                        and whether the values are considered a guaranteed API.
                        The value should be a CamelCase string.
                        This field may not be empty.
                      maxLength: 1024
                      minLength: 1
                      pattern: ^[A-Za-z]([A-Za-z0-9_,:]*[A-Za-z0-9_])?$
                      type: string
                    status:
                      description: status of the condition, one of True, False, Unknown.
                      enum:
                      - "True"
                      - "False"
                      - Unknown
                      type: string
                    type:
                      description: type of condition in CamelCase or in foo.example.com/CamelCase.
                      maxLength: 316
                      pattern: ^([a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*/)?(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])$
                      type: string
                  required:
                  - lastTransitionTime
                  - message
                  - reason
                  - status
                  - type
                  type: object
                type: array
              persesDashboardSynchronizationResults:
                additionalProperties:
                  properties:
                    dash0Dataset:
                      type: string
                    dash0Origin:
                      type: string
                    synchronizationError:
                      type: string
                    synchronizationStatus:
                      description: |-
                        ThirdPartySynchronizationStatus describes the result of synchronizing a third-party Kubernetes resource (Perses
                        dashboard, Prometheus rule) to the Dash0 API.
                      enum:
                      - successful
                      - partially-successful
                      - failed
                      type: string
                    synchronizedAt:
                      format: date-time
                      type: string
                    validationIssues:
                      items:
                        type: string
                      type: array
                  required:
                  - synchronizationStatus
                  - synchronizedAt
                  type: object
                description: Shows results of synchronizing Perses dashboard resources
                  in this namespace via the Dash0 API.
                type: object
              previousInstrumentWorkloads:
                description: The spec.instrumentWorkloads settings that have been
                  observed in the previous reconcile cycle.
                enum:
                - all
                - created-and-updated
                - none
                type: string
              prometheusRuleSynchronizationResults:
                additionalProperties:
                  properties:
                    alertingRulesTotal:
                      type: integer
                    invalidRules:
                      additionalProperties:
                        items:
                          type: string
                        type: array
                      type: object
                    invalidRulesTotal:
                      type: integer
                    synchronizationErrors:
                      additionalProperties:
                        type: string
                      type: object
                    synchronizationErrorsTotal:
                      type: integer
                    synchronizationStatus:
                      description: |-
                        ThirdPartySynchronizationStatus describes the result of synchronizing a third-party Kubernetes resource (Perses
                        dashboard, Prometheus rule) to the Dash0 API.
                      enum:
                      - successful
                      - partially-successful
                      - failed
                      type: string
                    synchronizedAt:
                      format: date-time
                      type: string
                    synchronizedRulesAttributes:
                      additionalProperties:
                        properties:
                          dash0Dataset:
                            type: string
                          dash0Origin:
                            type: string
                        type: object
                      type: object
                    synchronizedRulesTotal:
                      type: integer
                  required:
                  - alertingRulesTotal
                  - invalidRulesTotal
                  - synchronizationErrorsTotal
                  - synchronizationStatus
                  - synchronizedAt
                  - synchronizedRulesTotal
                  type: object
                description: Shows results of synchronizing Prometheus rule resources
                  in this namespace via the Dash0 API.
                type: object
            type: object
        type: object
    served: true
    storage: false
    subresources:
      status: {}
  - additionalPrinterColumns:
    - jsonPath: .spec.instrumentWorkloads.mode
      name: Instrument Workloads
      type: string
    - jsonPath: .spec.logCollection.enabled
      name: Collect Logs
      type: boolean
    - jsonPath: .spec.prometheusScraping.enabled
      name: Prometheus Scraping
      type: boolean
    - jsonPath: .status.conditions[?(@.type == "Available")].status
      name: Available
      type: string
    - jsonPath: .metadata.creationTimestamp
      name: Age
      type: date
    name: v1beta1
    schema:
      openAPIV3Schema:
        description: Dash0Monitoring is the schema for the Dash0Monitoring API
        properties:
          apiVersion:
            description: |-
              APIVersion defines the versioned schema of this representation of an object.
              Servers should convert recognized schemas to the latest internal value, and
              may reject unrecognized values.
              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
            type: string
          kind:
            description: |-
              Kind is a string value representing the REST resource this object represents.
              Servers may infer this from the endpoint the client submits requests to.
              Cannot be updated.
              In CamelCase.
              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
            type: string
          metadata:
            type: object
          spec:
            description: |-
              Dash0MonitoringSpec describes the details of monitoring a single Kubernetes namespace with Dash0 and sending
              telemetry to an observability backend.
            properties:
              __dash0_internal__normalizedTransform:
                description: Only used internally, this field must not be specified
                  by users.
                properties:
                  error_mode:
                    description: |-
                      FilterTransformErrorMode determine how the filter or the transform processor reacts to errors that occur while
                      processing a condition.
                    enum:
                    - ignore
                    - silent
                    - propagate
                    type: string
                  log_statements:
                    items:
                      properties:
                        conditions:
                          items:
                            type: string
                          type: array
                        context:
                          type: string
                        error_mode:
                          description: |-
                            FilterTransformErrorMode determine how the filter or the transform processor reacts to errors that occur while
                            processing a condition.
                          enum:
                          - ignore
                          - silent
                          - propagate
                          type: string
                        statements:
                          items:
                            type: string
                          type: array
                      type: object
                    type: array
                  metric_statements:
                    items:
                      properties:
                        conditions:
                          items:
                            type: string
                          type: array
                        context:
                          type: string
                        error_mode:
                          description: |-
                            FilterTransformErrorMode determine how the filter or the transform processor reacts to errors that occur while
                            processing a condition.
                          enum:
                          - ignore
                          - silent
                          - propagate
                          type: string
                        statements:
                          items:
                            type: string
                          type: array
                      type: object
                    type: array
                  trace_statements:
                    items:
                      properties:
                        conditions:
                          items:
                            type: string
                          type: array
                        context:
                          type: string
                        error_mode:
                          description: |-
                            FilterTransformErrorMode determine how the filter or the transform processor reacts to errors that occur while
                            processing a condition.
                          enum:
                          - ignore
                          - silent
                          - propagate
                          type: string
                        statements:
                          items:
                            type: string
                          type: array
                      type: object
                    type: array
                type: object
              export:
                description: |-
                  The configuration of the observability backend to which telemetry data will be sent. This property is optional.
                  If not set, the operator will use the default export configuration from the cluster-wide
                  Dash0OperatorConfiguration resource, if present. If no Dash0OperatorConfiguration resource has been created for
                  the cluster, or if the Dash0OperatorConfiguration resource does not have at least one export defined, creating a
                  Dash0Monitoring resource without export settings will result in an error.

                  The export can either be Dash0 or another OTLP-compatible backend. You can also combine up to three exporters
                  (i.e. Dash0 plus gRPC plus HTTP). This allows sending the same data to two or three targets simultaneously. When
                  the export setting is present, it has to contain at least one exporter.
                minProperties: 1
                properties:
                  dash0:
                    description: The configuration of the Dash0 ingress endpoint to
                      which telemetry data will be sent.
                    properties:
                      apiEndpoint:
                        description: |-
                          The base URL of the Dash0 API to talk to. This is not where telemetry will be sent, but it is used for managing
                          dashboards, check rules, synthetic checks and views via the operator. This property is optional. The value
                          needs to be the API endpoint of your Dash0 organization. The correct API endpoint can be copied fom
                          https://app.dash0.com -> organization settings -> "Endpoints" -> "API". The correct endpoint value will always
                          start with "https://api." and end in ".dash0.com"
                        type: string
                      authorization:
                        description: Mandatory authorization settings for sending
                          data to Dash0.
                        maxProperties: 1
                        minProperties: 1
                        properties:
                          secretRef:
                            description: |-
                              A reference to a Kubernetes secret containing the Dash0 authorization token. This property is optional, and is
                              ignored if the token property is set. The authorization token for your Dash0 organization can be copied from
                              https://app.dash0.com -> organization settings -> "Auth Tokens".
                            properties:
                              key:
                                default: token
                                description: The key of the value which contains the
                                  Dash0 authorization token. Defaults to "token"
                                type: string
                              name:
                                default: dash0-authorization-secret
                                description: The name of the secret containing the
                                  Dash0 authorization token. Defaults to "dash0-authorization-secret".
                                type: string
                            required:
                            - key
                            - name
                            type: object
                          token:
                            description: |-
                              The Dash0 authorization token. This property is optional, but either this property or the SecretRef property has
                              to be provided. If both are provided, the token will be used and SecretRef will be ignored. The authorization
                              token for your Dash0 organization can be copied from https://app.dash0.com -> organization settings ->
                              "Auth Tokens".
                            type: string
                        type: object
                      dataset:
                        default: default
                        description: |-
                          The name of the Dash0 dataset to which telemetry data will be sent. This property is optional. If omitted, the
                          dataset "default" will be used.
                        type: string
                      endpoint:
                        description: |-
                          The URL of the Dash0 ingress endpoint to which telemetry data will be sent. This property is mandatory. The value
                          needs to be the OTLP/gRPC endpoint of your Dash0 organization. The correct OTLP/gRPC endpoint can be copied fom
                          https://app.dash0.com -> organization settings -> "Endpoints". The correct endpoint value will always start with
                          `ingress.` and end in `dash0.com:4317`.
                        minLength: 1
                        type: string
                    required:
                    - authorization
                    - endpoint
                    type: object
                  grpc:
                    description: The settings for an exporter to send telemetry to
                      an arbitrary OTLP-compatible receiver via gRPC.
                    properties:
                      endpoint:
                        description: The URL of the OTLP-compatible receiver to which
                          telemetry data will be sent. This property is mandatory.
                        type: string
                      headers:
                        description: Additional headers to be sent with each gRPC
                          request, for example for authorization. This property is
                          optional.
                        items:
                          properties:
                            name:
                              type: string
                            value:
                              type: string
                          required:
                          - name
                          - value
                          type: object
                        type: array
                      insecure:
                        description: Explicitly defines whether TLS is used. Per default,
                          a secure connection is assumed, unless the endpoint starts
                          with 'http://'.
                        type: boolean
                      insecureSkipVerify:
                        description: |-
                          Whether to skip verifying the server's certificate chain. It is a validation error to explicitly set
                          `insecure=true` and `insecureSkipVerify=true` at the same time, since `insecure` means TLS won't be used at all.
                        type: boolean
                    required:
                    - endpoint
                    type: object
                  http:
                    description: The settings for an exporter to send telemetry to
                      an arbitrary OTLP-compatible receiver via HTTP.
                    properties:
                      encoding:
                        default: proto
                        description: The encoding of the OTLP data when sent via HTTP.
                          Can be either proto or json, defaults to proto.
                        enum:
                        - proto
                        - json
                        type: string
                      endpoint:
                        description: The URL of the OTLP-compatible receiver to which
                          telemetry data will be sent. This property is mandatory.
                        type: string
                      headers:
                        description: Additional headers to be sent with each HTTP
                          request, for example for authorization. This property is
                          optional.
                        items:
                          properties:
                            name:
                              type: string
                            value:
                              type: string
                          required:
                          - name
                          - value
                          type: object
                        type: array
                      insecureSkipVerify:
                        description: Whether verification of TLS certificates should
                          be skipped. Ignored when the endpoint uses an insecure connection.
                        type: boolean
                    required:
                    - endpoint
                    type: object
                type: object
              filter:
                description: |-
                  Optional filters for telemetry data that is collected in this namespace. This can be used to drop entire spans,
                  span events, metrics, metric data points, or log records. See "Transform" for advanced transformations (e.g.
                  removing span attributes, metric data point attributes, log record attributes etc.). This setting is optional,
                  by default, no filters are applied. It is a validation error to set `telemetryCollection.enabled=false` in the
                  operator configuration resource and set filters in any monitoring resource at the same time.
                properties:
                  error_mode:
                    default: ignore
                    description: |-
                      An optional field which will determine how the filter processor reacts to errors that occur while processing a
                      condition. Possible values:
                      - ignore: ignore errors returned by conditions, log them, continue with to the next condition.
                                This is the recommended mode and also the default mode if this property is omitted.
                      - silent: ignore errors returned by conditions, do not log them, continue with to the next condition.
                      - propagate: return the error up the processing pipeline. This will result in the payload being dropped from the
                                collector. Not recommended.

                      This is optional, default to "ignore", there is usually no reason to change this.

                      Note that although this can be specified per namespace, the filter conditions will be aggregated into one
                      single filter processor in the resulting OpenTelemetry collector configuration; if different error modes are
                      specified in different namespaces, the "most severe" error mode will be used (propagate > ignore > silent).
                    enum:
                    - ignore
                    - silent
                    - propagate
                    type: string
                  logs:
                    description: |-
                      Filters for the logs signal.
                      This can be used to drop _log records_.
                    properties:
                      log_records:
                        description: |-
                          A list of conditions for filtering log records.
                          This is a list of OTTL conditions.
                          All log records where at least one condition evaluates to true will be dropped.
                          (That is, the conditions are implicitly connected by a logical OR.)
                          Example:
                          - 'IsMatch(body, ".*password.*")'
                          - 'severity_number < SEVERITY_NUMBER_WARN'
                        items:
                          type: string
                        type: array
                    type: object
                  metrics:
                    description: |-
                      Filters for the metrics signal.
                      This can be used to drop entire _metrics_, or individual _data points_.
                    properties:
                      datapoint:
                        description: |-
                          A list of conditions for filtering metrics data points.
                          This is a list of OTTL conditions.
                          All data points where at least one condition evaluates to true will be dropped.
                          (That is, the conditions are implicitly connected by a logical OR.)
                          Note: If all datapoints for a metric are dropped, the metric will also be dropped.
                          Example:
                          - 'metric.name == "a.noisy.metric.with.many.datapoints" and value_int == 0' # filter metrics by value
                          - 'resource.attributes["service.name"] == "my_service_name"' # filter data points by resource attributes
                        items:
                          type: string
                        type: array
                      metric:
                        description: |-
                          A list of conditions for filtering metrics.
                          This is a list of OTTL conditions.
                          All metrics where at least one condition evaluates to true will be dropped.
                          (That is, the conditions are implicitly connected by a logical OR.)
                          Example:
                          - 'name == "k8s.replicaset.available"'
                          - 'name == "k8s.replicaset.desired"'
                          - 'type == METRIC_DATA_TYPE_HISTOGRAM'
                        items:
                          type: string
                        type: array
                    type: object
                  traces:
                    description: |-
                      Filters for the traces signal.
                      This can be used to drop _spans_ or _span events_.
                    properties:
                      span:
                        description: |-
                          A list of conditions for filtering spans.
                          This is a list of OTTL conditions.
                          All spans where at least one condition evaluates to true will be dropped.
                          (That is, the conditions are implicitly connected by a logical OR.)
                          Example:
                          - 'attributes["http.route"] == "/ready"'
                          - 'attributes["http.route"] == "/metrics"'
                        items:
                          type: string
                        type: array
                      spanevent:
                        description: |-
                          A list of conditions for filtering span events.
                          This is a list of OTTL conditions.
                          All span events where at least one condition evaluates to true will be dropped.
                          (That is, the conditions are implicitly connected by a logical OR.)
                          If all span events for a span are dropped, the span will be left intact.
                        items:
                          type: string
                        type: array
                    type: object
                type: object
              instrumentWorkloads:
                description: |-
                  Settings for automatic instrumentation of workloads in the target namespace. This setting is optional, by default
                  the operator will instrument existing workloads, as well as new workloads at deploy time and changed workloads
                  when they are updated.
                properties:
                  labelSelector:
                    default: dash0.com/enable!=false
                    description: |-
                      An optional configurable label selector for fine-grained per-workload control over instrumentation. Workloads
                      which match this label selector will be instrumented (according to the value of spec.instrumentWorkloads.mode).
                      Workloads which do not match this label selector will never be instrumented, regardless of the value of
                      spec.instrumentWorkloads.mode.

                      This attribute is ignored if spec.instrumentWorkloads.mode=none.

                      By default, this label selector has the value "dash0.com/enable!=false" - that is, the following workloads will
                      be instrumented (assuming spec.instrumentWorkloads.mode!=none)
                      - workloads that do not have the label dash0.com/enable at all, or
                      - workloads that have the label dash0.com/enable with a value other than "false".

                      It is recommended to leave this setting unset (i.e. leave the default "dash0.com/enable!=false" in place), unless
                      you have a specific use case that requires a different label selector. One such use case is implementing an
                      opt-in model for workload instrumentation instead of the usual opt-out model. That is, instead of instrumenting
                      all workloads by default and only disabling instrumentation for a few specific workloads, you want to
                      deliberately turn on instrumentation for a few specific workloads and leave all others uninstrumented. Use a
                      label selector with equals instead of not-equals to achieve this, i.e.
                      spec.instrumentWorkloads.labelSelector="auto-instrument-this-workload-with-dash0=true".
                    type: string
                  mode:
                    description: |-
                      Controls the automatic workload instrumentation triggers for the target namespace, that is, which events will
                      trigger the auto-instrumentation of a workload. There are three possible
                      settings:
                      `all`, `created-and-updated` and `none`. By default, the setting `all` is assumed, unless there is an operator
                      configuration resource with `telemetryCollection.enabled=false`, then the setting `none` is assumed.

                      If set to `all`, the operator will:
                      * automatically instrument existing workloads in the target namespace (i.e. workloads already running in the
                        namespace) when the Dash0 monitoring resource is deployed,
                      * instrument existing workloads or update the instrumentation of already instrumented workloads in the target
                        namespace when the Dash0 operator is first started or restarted (for example when updating the operator),
                      * instrument new workloads in the target namespace when they are deployed, and
                      * instrument changed workloads in the target namespace when changes are applied to them.
                      Note that the first two actions (instrumenting existing workloads) will result in restarting the pods of the
                      affected workloads.

                      If set to `created-and-updated`, the operator will not instrument existing workloads in the target namespace,
                      neither when a Dash0 monitoring resource is deployed, nor when the Dash0 operator is started or restarted.
                      Instead, it will only:
                      * instrument new workloads in the target namespace when they are deployed, and
                      * instrument changed workloads in the target namespace when changes are applied to them.
                      This setting is useful if you want to avoid pod restarts as a side effect of deploying the Dash0 monitoring
                      resource or restarting the Dash0 operator.

                      You can opt out of automatically instrumenting workloads entirely by setting this option to `none`. With
                      `mode: none`, workloads in the target namespace will never be instrumented to send telemetry to Dash0.

                      If this setting is omitted, the value `all` is assumed and new, updated as well as existing Kubernetes workloads
                      will be automatically intrumented by the operator to send telemetry to Dash0, as described above. There is one
                      exception to this rule: If there is an operator configuration resource with `telemetryCollection.enabled=false`,
                      then the default setting is `none` instead of `all`, and no workloads will be instrumented by the Dash0 operator.

                      It is a validation error to set `telemetryCollection.enabled=false` in the operator configuration resource and
                      `mode: all` or `mode: created-and-updated` in any monitoring resource at the
                      same time.

                      More fine-grained per-workload control over instrumentation is available by setting the label
                      dash0.com/enable=false on individual workloads, or by using a custom label selector via
                      spec.instrumentWorkloads.labelSelector.
                    enum:
                    - all
                    - created-and-updated
                    - none
                    type: string
                  traceContext:
                    description: Optional settings for how trace context is handled
                      in instrumented workloads.
                    properties:
                      propagators:
                        description: |-
                          An optional comma-separated list of trace context propagators. If set, the environment variable OTEL_PROPAGATORS
                          is added to workloads with the value of this field. This allows configuring the OpenTelemetry SDK to use specific
                          propagators for trace context propagation. The value can be a comma-separated list of propagators, for exampmle
                          "tracecontext,xray" for the W3C trace context traceparent header and AWS X-Ray headers.

                          Note that you usually want to list the preferred propagator last, if multiple propagators are specified. The
                          reason is that both `Extract` (reading trace context information from headers and adding it to the span) and
                          `Inject` (addding trace context information to headers on outgoing requests) are both run in the order in which
                          the propagators are defined. For extract that means that the _last one wins_, if multiple propagators extract the
                          same information (e.g. trace ID and span ID). Hence, the need to specify them in reverse order of priority.

                          By default, the value is not set and the environment variable OTEL_PROPAGATORS will not be added to workloads.
                          (The default values for OpenTelemetry SDKs when OTEL_PROPAGATORS is not set is "tracecontext,baggage".)

                          See also: https://opentelemetry.io/docs/languages/sdk-configuration/general/#otel_propagators
                        type: string
                    type: object
                type: object
              logCollection:
                description: |-
                  Settings for log collection in the target namespace. This setting is optional, by default the operator will
                  collect pod logs in the target namespace; unless there is an operator configuration resource with
                  `telemetryCollection.enabled=false`, then log collection is off by default. It is a validation error to set
                  `telemetryCollection.enabled=false` in the operator configuration resource and `logCollection.enabled=true` in any
                  monitoring resource at the same time.
                properties:
                  enabled:
                    description: |-
                      Opt-out for log collection for the target namespace. If set to `false`, the operator will not collect pod logs
                      in the target namespace and send the resulting log records to Dash0.

                      This setting is optional, it defaults to `true`, that is, if this setting is omitted, the value `true` is assumed
                      and the operator will collect pod logs in the target namespace; unless there is an operator configuration
                      resource with `telemetryCollection.enabled=false`, then log collection is off by default. It is a validation error
                      to set `telemetryCollection.enabled=false` in the operator configuration resource and
                      `logCollection.enabled=true` in any monitoring resource at the same time.
                    type: boolean
                type: object
              prometheusScraping:
                description: |-
                  Settings for scraping Prometheus metrics from pods in the target namespace according to their
                  prometheus.io/scrape annotations. This setting is optional, by default the operator will scrape metrics from pods
                  with these notations in the target namespace; unless there is an operator configuration resource with
                  `telemetryCollection.enabled=false`, then Prometheus scraping is off by default. It is a validation error to set
                  `telemetryCollection.enabled=false` in the operator configuration resource and `prometheusScraping.enabled=true`
                  in any monitoring resource at the same time.
                properties:
                  enabled:
                    description: |-
                      If enabled, the operator will configure its OpenTelemetry collector to scrape metrics from pods in the namespace
                      of this Dash0Monitoring resource according to their prometheus.io/scrape annotations via the OpenTelemetry
                      Prometheus receiver. This setting is optional, it defaults to `true`; unless there is an operator configuration
                      resource with `telemetryCollection.enabled=false`, then Prometheus scraping is off by default. It is a validation
                      error to set `telemetryCollection.enabled=false` in the operator configuration resource and
                      `prometheusScraping.enabled=true` in any monitoring resource at the same time.
                    type: boolean
                type: object
              synchronizePersesDashboards:
                default: true
                description: |-
                  If enabled, the operator will watch Perses dashboard resources in this namespace and create corresponding
                  dashboards in Dash0 via the Dash0 API.
                  See https://github.com/dash0hq/dash0-operator/blob/main/helm-chart/dash0-operator/README.md#managing-dash0-dashboards-with-the-operator
                  for details. This setting is optional, it defaults to `true`.
                type: boolean
              synchronizePrometheusRules:
                default: true
                description: |-
                  If enabled, the operator will watch Prometheus rule resources in this namespace and create corresponding check
                  rules in Dash0 via the Dash0 API.
                  See https://github.com/dash0hq/dash0-operator/blob/main/helm-chart/dash0-operator/README.md#managing-dash0-check-rules-with-the-operator
                  for details. This setting is optional, it defaults to `true`.
                type: boolean
              transform:
                description: |-
                  Optional custom transformations for telemetry data that is collected in this namespace. This can be used to
                  remove span attributes, metric data point attributes, log record attributes etc. See "Filter" for basic filters
                  that can be used to drop entire spans, span events, metrics, metric data points, or log records.

                  For each signal type (traces, metrics, logs), a list of OTTL statements can be defined. These will be applied to
                  the telemetry collected in the namespace, following the order specified in the configuration. Each statement can
                  access and transform telemetry using OTTL functions.
                  See https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/transformprocessor
                  for details and examples. Note that this configuration currently supports the
                  [basic config style](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/transformprocessor/README.md#basic-config)
                  of the transform processor. The
                  [advanced config style](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/transformprocessor/README.md#advanced-config)
                  is not supported.

                  This setting is optional, by default, no transformations are applied. It is a validation error to set
                  `telemetryCollection.enabled=false` in the operator configuration resource and set transforms in any monitoring
                  resource at the same time.
                properties:
                  error_mode:
                    default: ignore
                    description: |-
                      An optional field which will determine how the transform processor reacts to errors that occur while processing a
                      statement. Possible values:
                      - ignore: ignore errors returned by statements, log them, continue with to the next statement.
                      - silent: ignore errors returned by statements, do not log them, continue with to the next statement.
                      - propagate: return the error up the processing pipeline. This will result in the payload being dropped from the
                        collector.

                      This is optional, default to "ignore".

                      Note that although this can be specified per namespace, the transform statements will be aggregated into one
                      single transform processor in the resulting OpenTelemetry collector configuration; if different error modes are
                      specified in different namespaces, the "most severe" error mode will be used (propagate > ignore > silent).
                    enum:
                    - ignore
                    - silent
                    - propagate
                    type: string
                  log_statements:
                    description: Transform statements (or groups) for the log signal
                      type.
                    x-kubernetes-preserve-unknown-fields: true
                  metric_statements:
                    description: Transform statements (or groups) for the metric signal
                      type.
                    x-kubernetes-preserve-unknown-fields: true
                  trace_statements:
                    description: Transform statements (or groups) for the trace signal
                      type.
                    x-kubernetes-preserve-unknown-fields: true
                type: object
            type: object
          status:
            description: Dash0MonitoringStatus defines the observed state of the Dash0Monitoring
              monitoring resource.
            properties:
              conditions:
                items:
                  description: "Condition contains details for one aspect of the current
                    state of this API Resource.\n---\nThis struct is intended for
                    direct use as an array at the field path .status.conditions.  For
                    example,\n\n\n\ttype FooStatus struct{\n\t    // Represents the
                    observations of a foo's current state.\n\t    // Known .status.conditions.type
                    are: \"Available\", \"Progressing\", and \"Degraded\"\n\t    //
                    +patchMergeKey=type\n\t    // +patchStrategy=merge\n\t    // +listType=map\n\t
                    \   // +listMapKey=type\n\t    Conditions []metav1.Condition `json:\"conditions,omitempty\"
                    patchStrategy:\"merge\" patchMergeKey:\"type\" protobuf:\"bytes,1,rep,name=conditions\"`\n\n\n\t
                    \   // other fields\n\t}"
                  properties:
                    lastTransitionTime:
                      description: |-
                        lastTransitionTime is the last time the condition transitioned from one status to another.
                        This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
                      format: date-time
                      type: string
                    message:
                      description: |-
                        message is a human readable message indicating details about the transition.
                        This may be an empty string.
                      maxLength: 32768
                      type: string
                    observedGeneration:
                      description: |-
                        observedGeneration represents the .metadata.generation that the condition was set based upon.
                        For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date
                        with respect to the current state of the instance.
                      format: int64
                      minimum: 0
                      type: integer
                    reason:
                      description: |-
                        reason contains a programmatic identifier indicating the reason for the condition's last transition.
                        Producers of specific condition types may define expected values and meanings for this field,
                        and whether the values are considered a guaranteed API.
                        The value should be a CamelCase string.
                        This field may not be empty.
                      maxLength: 1024
                      minLength: 1
                      pattern: ^[A-Za-z]([A-Za-z0-9_,:]*[A-Za-z0-9_])?$
                      type: string
                    status:
                      description: status of the condition, one of True, False, Unknown.
                      enum:
                      - "True"
                      - "False"
                      - Unknown
                      type: string
                    type:
                      description: type of condition in CamelCase or in foo.example.com/CamelCase.
                      maxLength: 316
                      pattern: ^([a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*/)?(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])$
                      type: string
                  required:
                  - lastTransitionTime
                  - message
                  - reason
                  - status
                  - type
                  type: object
                type: array
              persesDashboardSynchronizationResults:
                additionalProperties:
                  properties:
                    dash0Dataset:
                      type: string
                    dash0Origin:
                      type: string
                    synchronizationError:
                      type: string
                    synchronizationStatus:
                      description: |-
                        ThirdPartySynchronizationStatus describes the result of synchronizing a third-party Kubernetes resource (Perses
                        dashboard, Prometheus rule) to the Dash0 API.
                      enum:
                      - successful
                      - partially-successful
                      - failed
                      type: string
                    synchronizedAt:
                      format: date-time
                      type: string
                    validationIssues:
                      items:
                        type: string
                      type: array
                  required:
                  - synchronizationStatus
                  - synchronizedAt
                  type: object
                description: Shows results of synchronizing Perses dashboard resources
                  in this namespace via the Dash0 API.
                type: object
              previousInstrumentWorkloads:
                description: The spec.instrumentWorkloads.mode setting that has been
                  observed in the previous reconcile cycle.
                properties:
                  labelSelector:
                    default: dash0.com/enable!=false
                    description: |-
                      An optional configurable label selector for fine-grained per-workload control over instrumentation. Workloads
                      which match this label selector will be instrumented (according to the value of spec.instrumentWorkloads.mode).
                      Workloads which do not match this label selector will never be instrumented, regardless of the value of
                      spec.instrumentWorkloads.mode.

                      This attribute is ignored if spec.instrumentWorkloads.mode=none.

                      By default, this label selector has the value "dash0.com/enable!=false" - that is, the following workloads will
                      be instrumented (assuming spec.instrumentWorkloads.mode!=none)
                      - workloads that do not have the label dash0.com/enable at all, or
                      - workloads that have the label dash0.com/enable with a value other than "false".

                      It is recommended to leave this setting unset (i.e. leave the default "dash0.com/enable!=false" in place), unless
                      you have a specific use case that requires a different label selector. One such use case is implementing an
                      opt-in model for workload instrumentation instead of the usual opt-out model. That is, instead of instrumenting
                      all workloads by default and only disabling instrumentation for a few specific workloads, you want to
                      deliberately turn on instrumentation for a few specific workloads and leave all others uninstrumented. Use a
                      label selector with equals instead of not-equals to achieve this, i.e.
                      spec.instrumentWorkloads.labelSelector="auto-instrument-this-workload-with-dash0=true".
                    type: string
                  mode:
                    description: |-
                      Controls the automatic workload instrumentation triggers for the target namespace, that is, which events will
                      trigger the auto-instrumentation of a workload. There are three possible
                      settings:
                      `all`, `created-and-updated` and `none`. By default, the setting `all` is assumed, unless there is an operator
                      configuration resource with `telemetryCollection.enabled=false`, then the setting `none` is assumed.

                      If set to `all`, the operator will:
                      * automatically instrument existing workloads in the target namespace (i.e. workloads already running in the
                        namespace) when the Dash0 monitoring resource is deployed,
                      * instrument existing workloads or update the instrumentation of already instrumented workloads in the target
                        namespace when the Dash0 operator is first started or restarted (for example when updating the operator),
                      * instrument new workloads in the target namespace when they are deployed, and
                      * instrument changed workloads in the target namespace when changes are applied to them.
                      Note that the first two actions (instrumenting existing workloads) will result in restarting the pods of the
                      affected workloads.

                      If set to `created-and-updated`, the operator will not instrument existing workloads in the target namespace,
                      neither when a Dash0 monitoring resource is deployed, nor when the Dash0 operator is started or restarted.
                      Instead, it will only:
                      * instrument new workloads in the target namespace when they are deployed, and
                      * instrument changed workloads in the target namespace when changes are applied to them.
                      This setting is useful if you want to avoid pod restarts as a side effect of deploying the Dash0 monitoring
                      resource or restarting the Dash0 operator.

                      You can opt out of automatically instrumenting workloads entirely by setting this option to `none`. With
                      `mode: none`, workloads in the target namespace will never be instrumented to send telemetry to Dash0.

                      If this setting is omitted, the value `all` is assumed and new, updated as well as existing Kubernetes workloads
                      will be automatically intrumented by the operator to send telemetry to Dash0, as described above. There is one
                      exception to this rule: If there is an operator configuration resource with `telemetryCollection.enabled=false`,
                      then the default setting is `none` instead of `all`, and no workloads will be instrumented by the Dash0 operator.

                      It is a validation error to set `telemetryCollection.enabled=false` in the operator configuration resource and
                      `mode: all` or `mode: created-and-updated` in any monitoring resource at the
                      same time.

                      More fine-grained per-workload control over instrumentation is available by setting the label
                      dash0.com/enable=false on individual workloads, or by using a custom label selector via
                      spec.instrumentWorkloads.labelSelector.
                    enum:
                    - all
                    - created-and-updated
                    - none
                    type: string
                  traceContext:
                    description: Optional settings for how trace context is handled
                      in instrumented workloads.
                    properties:
                      propagators:
                        description: |-
                          An optional comma-separated list of trace context propagators. If set, the environment variable OTEL_PROPAGATORS
                          is added to workloads with the value of this field. This allows configuring the OpenTelemetry SDK to use specific
                          propagators for trace context propagation. The value can be a comma-separated list of propagators, for exampmle
                          "tracecontext,xray" for the W3C trace context traceparent header and AWS X-Ray headers.

                          Note that you usually want to list the preferred propagator last, if multiple propagators are specified. The
                          reason is that both `Extract` (reading trace context information from headers and adding it to the span) and
                          `Inject` (addding trace context information to headers on outgoing requests) are both run in the order in which
                          the propagators are defined. For extract that means that the _last one wins_, if multiple propagators extract the
                          same information (e.g. trace ID and span ID). Hence, the need to specify them in reverse order of priority.

                          By default, the value is not set and the environment variable OTEL_PROPAGATORS will not be added to workloads.
                          (The default values for OpenTelemetry SDKs when OTEL_PROPAGATORS is not set is "tracecontext,baggage".)

                          See also: https://opentelemetry.io/docs/languages/sdk-configuration/general/#otel_propagators
                        type: string
                    type: object
                type: object
              prometheusRuleSynchronizationResults:
                additionalProperties:
                  properties:
                    alertingRulesTotal:
                      type: integer
                    invalidRules:
                      additionalProperties:
                        items:
                          type: string
                        type: array
                      type: object
                    invalidRulesTotal:
                      type: integer
                    synchronizationErrors:
                      additionalProperties:
                        type: string
                      type: object
                    synchronizationErrorsTotal:
                      type: integer
                    synchronizationStatus:
                      description: |-
                        ThirdPartySynchronizationStatus describes the result of synchronizing a third-party Kubernetes resource (Perses
                        dashboard, Prometheus rule) to the Dash0 API.
                      enum:
                      - successful
                      - partially-successful
                      - failed
                      type: string
                    synchronizedAt:
                      format: date-time
                      type: string
                    synchronizedRulesAttributes:
                      additionalProperties:
                        properties:
                          dash0Dataset:
                            type: string
                          dash0Origin:
                            type: string
                        type: object
                      type: object
                    synchronizedRulesTotal:
                      type: integer
                  required:
                  - alertingRulesTotal
                  - invalidRulesTotal
                  - synchronizationErrorsTotal
                  - synchronizationStatus
                  - synchronizedAt
                  - synchronizedRulesTotal
                  type: object
                description: Shows results of synchronizing Prometheus rule resources
                  in this namespace via the Dash0 API.
                type: object
            type: object
        type: object
    served: true
    storage: true
    subresources:
      status: {}

{{/*
Maintenance note: When synchronizing helm-chart/dash0-operator/templates/operator/deployment-and-webhooks.yaml
with config/crd/bases/operator.dash0.com_dash0monitorings.yaml after changing the CRD Golang types under
api/operator, note that the the conversion webhook will not be generated in
config/crd/bases/operator.dash0.com_dash0monitorings.yaml; hence, this diff is to be ignored.
*/}}
  conversion:
    strategy: Webhook
    webhook:
      conversionReviewVersions:
      - v1
      clientConfig:
        {{- if not .Values.operator.certManager.useCertManager }}
        caBundle: {{ default "" ( $ca.Cert | b64enc ) }}
        {{- end }}
        service:
          name: {{ template "dash0-operator.webhookServiceName" . }}
          namespace: {{ .Release.Namespace }}
          port: {{ template "dash0-operator.webhookServicePort" . }}
{{/*
Looks like it is currently not possible to convince controller-runtime to serve the conversion webhook at a different
path than "/convert". Something like "/monitoring/conversion" would be better. This might become an issue once we need
a conversion webhook for the Dash0OperatorConfiguration resource as well.
*/}}
          path: /convert
